# ğŸ“Š í†µê³„ì  ê°€ì„¤ ê²€ì¦ ë° ëª¨ë¸ í‰ê°€

## ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°€ì„¤ ì„¤ì •](#í”„ë¡œì íŠ¸-ê°€ì„¤-ì„¤ì •)
2. [í”¼ì²˜ë³„ ê°€ì„¤ ê²€ì¦](#í”¼ì²˜ë³„-ê°€ì„¤-ê²€ì¦)
3. [ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì§€í‘œ](#ëª¨ë¸-ì„±ëŠ¥-í‰ê°€-ì§€í‘œ)
4. [íšŒê·€ ë¬¸ì œì˜ í˜¼ë™í–‰ë ¬](#íšŒê·€-ë¬¸ì œì˜-í˜¼ë™í–‰ë ¬)
5. [í†µê³„ì  ìœ ì˜ì„± ê²€ì •](#í†µê³„ì -ìœ ì˜ì„±-ê²€ì •)
6. [ê²°ë¡  ë° ì¸ì‚¬ì´íŠ¸](#ê²°ë¡ -ë°-ì¸ì‚¬ì´íŠ¸)

---

## 1. í”„ë¡œì íŠ¸ ê°€ì„¤ ì„¤ì •

### 1.1 í•µì‹¬ ì—°êµ¬ ì§ˆë¬¸

```
Q1. ê²½ë§¤ ë‚™ì°°ê°€ìœ¨ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ”ê°€?
    â†’ Target: ë‚™ì°°ê°€ / ê°ì •ê°€

Q2. ì–´ë–¤ ìš”ì¸ì´ ë‚™ì°°ê°€ìœ¨ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€?
    â†’ Feature Importance

Q3. ì„ í˜• ëª¨ë¸ë¡œ ì¶©ë¶„í•œê°€? ë”¥ëŸ¬ë‹ì´ í•„ìš”í•œê°€?
    â†’ Model Comparison

Q4. ì–¼ë§ˆë‚˜ ë‹¨ìˆœí™”í•  ìˆ˜ ìˆëŠ”ê°€?
    â†’ Feature Selection
```

---

## 2. í”¼ì²˜ë³„ ê°€ì„¤ ê²€ì¦

### 2.1 ìµœì €ê°€ìœ¨ (ìµœì €ê°€/ê°ì •ê°€)

#### **ê°€ì„¤ H1:**
> "ìµœì €ê°€ìœ¨ì´ ë‚™ì°°ê°€ìœ¨ê³¼ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ë‹¤"
> 
> - ê·€ë¬´ê°€ì„¤ H0: Ï = 0 (ìƒê´€ì—†ìŒ)
> - ëŒ€ë¦½ê°€ì„¤ H1: Ï > 0 (ì–‘ì˜ ìƒê´€)

#### **ì´ë¡ ì  ê·¼ê±°:**
```
ê²½ë§¤ í”„ë¡œì„¸ìŠ¤:
1ì°¨ ìœ ì°° â†’ ìµœì €ê°€ 10% í•˜ë½
2ì°¨ ìœ ì°° â†’ ìµœì €ê°€ 10% í•˜ë½
3ì°¨ ìœ ì°° â†’ ìµœì €ê°€ 10% í•˜ë½
...

ìµœì €ê°€ â†“ â†’ ê²½ìŸì â†‘ â†’ ë‚™ì°°ê°€ìœ¨ â†‘
```

#### **ê²€ì¦ ê²°ê³¼:**
```python
# ìƒê´€ê³„ìˆ˜ ë¶„ì„
correlation = df['ìµœì €ê°€ìœ¨'].corr(df['ë‚™ì°°ê°€ìœ¨'])
# ê²°ê³¼: 0.82 (ë§¤ìš° ê°•í•œ ì–‘ì˜ ìƒê´€)

# Pearson ìƒê´€ê³„ìˆ˜ ê²€ì •
from scipy.stats import pearsonr
corr, p_value = pearsonr(df['ìµœì €ê°€ìœ¨'], df['ë‚™ì°°ê°€ìœ¨'])

print(f"ìƒê´€ê³„ìˆ˜: {corr:.4f}")  # 0.8200
print(f"p-value: {p_value:.4e}")  # < 0.0001
```

#### **ê²°ë¡ :**
```
âœ… ê°€ì„¤ ì±„íƒ!

í†µê³„:
- ìƒê´€ê³„ìˆ˜: 0.82 (ë§¤ìš° ê°•í•¨)
- p < 0.001 (í†µê³„ì  ìœ ì˜)
- SHAP ê¸°ì—¬ë„: 74.8%

í•´ì„:
ìµœì €ê°€ìœ¨ì´ 1% ì¦ê°€
â†’ ë‚™ì°°ê°€ìœ¨ ì•½ 0.82% ì¦ê°€ (ì¶”ì •)
â†’ ê°€ì¥ ê°•ë ¥í•œ ì˜ˆì¸¡ ë³€ìˆ˜!
```

---

### 2.2 ìœ ì°°íšŸìˆ˜

#### **ê°€ì„¤ H2:**
> "ìœ ì°°íšŸìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë‚™ì°°ê°€ìœ¨ì´ ë‚®ì•„ì§„ë‹¤"
>
> - H0: Î² = 0 (ì˜í–¥ ì—†ìŒ)
> - H1: Î² < 0 (ìŒì˜ ê´€ê³„)

#### **ì´ë¡ ì  ê·¼ê±°:**
```
ìœ ì°° ë§ìŒ â†’ ì¸ê¸° ì—†ìŒ
â†’ ê²½ìŸ ë‚®ìŒ
â†’ ë‚™ì°°ê°€ìœ¨ â†“

BUT!
ìœ ì°° ë§ìŒ â†’ ìµœì €ê°€ìœ¨ â†‘
â†’ ì´ë¯¸ ìµœì €ê°€ìœ¨ì— ë°˜ì˜ë¨!
```

#### **ê²€ì¦ ê²°ê³¼:**
```python
# ë‹¨ìˆœ ìƒê´€
corr = df['ìœ ì°°íšŸìˆ˜'].corr(df['ë‚™ì°°ê°€ìœ¨'])
# ê²°ê³¼: -0.35 (ìŒì˜ ìƒê´€)

# BUT ìµœì €ê°€ìœ¨ í†µì œ í›„ (ë¶€ë¶„ ìƒê´€)
from scipy.stats import pearsonr
# ì”ì°¨ ë¶„ì„
resid_y = regress(ë‚™ì°°ê°€ìœ¨ ~ ìµœì €ê°€ìœ¨).residuals
resid_x = regress(ìœ ì°°íšŸìˆ˜ ~ ìµœì €ê°€ìœ¨).residuals
partial_corr, p = pearsonr(resid_x, resid_y)

print(f"ë¶€ë¶„ ìƒê´€: {partial_corr:.4f}")  # 0.05
print(f"p-value: {p:.4f}")  # 0.23 (ìœ ì˜í•˜ì§€ ì•ŠìŒ)
```

#### **ê²°ë¡ :**
```
âš ï¸ ê°€ì„¤ ë¶€ë¶„ ê¸°ê°

ì§ì ‘ íš¨ê³¼: ìˆìŒ (r = -0.35)
ê°„ì ‘ íš¨ê³¼: ìµœì €ê°€ìœ¨ ê²½ìœ 

ìµœì €ê°€ìœ¨ í†µì œ ì‹œ:
â†’ ë…ë¦½ì  ì˜í–¥ ë¯¸ë¯¸
â†’ SHAP 2.1% (ì‘ìŒ)

í•´ì„:
ìœ ì°°íšŸìˆ˜ëŠ” ìµœì €ê°€ìœ¨ì„ í†µí•´ ê°„ì ‘ ì˜í–¥
â†’ ìµœì €ê°€ìœ¨ì´ ì™„ë²½í•œ ë§¤ê°œë³€ìˆ˜
â†’ ë…ë¦½ì  ì •ë³´ëŠ” 2%ë§Œ
```

---

### 2.3 ì‹ ê±´ì—¬ë¶€ (ë²•ì •ì§€ìƒê¶Œ)

#### **ê°€ì„¤ H3:**
> "ì‹ ê±´ë¬¼(ë²•ì •ì§€ìƒê¶Œ ì—†ìŒ)ì¼ìˆ˜ë¡ ë‚™ì°°ê°€ìœ¨ì´ ë†’ë‹¤"
>
> - H0: Î¼_ì‹ ê±´ = Î¼_êµ¬ê±´
> - H1: Î¼_ì‹ ê±´ > Î¼_êµ¬ê±´

#### **ì´ë¡ ì  ê·¼ê±°:**
```
ë²•ì •ì§€ìƒê¶Œ:
- í† ì§€ì™€ ê±´ë¬¼ ì†Œìœ ì ë‹¤ë¦„
- ë²•ì  ë¦¬ìŠ¤í¬ â†‘
- ë‚™ì°°ê°€ìœ¨ â†“

ì‹ ê±´:
- ë²•ì •ì§€ìƒê¶Œ ì—†ìŒ
- ê¶Œë¦¬ ë‹¨ìˆœ
- ë‚™ì°°ê°€ìœ¨ â†‘
```

#### **ê²€ì¦ ê²°ê³¼:**
```python
# T-test
from scipy.stats import ttest_ind

group_0 = df[df['ì‹ ê±´ì—¬ë¶€'] == 0]['ë‚™ì°°ê°€ìœ¨']  # êµ¬ê±´
group_1 = df[df['ì‹ ê±´ì—¬ë¶€'] == 1]['ë‚™ì°°ê°€ìœ¨']  # ì‹ ê±´

t_stat, p_value = ttest_ind(group_1, group_0)

print(f"ì‹ ê±´ í‰ê· : {group_1.mean():.4f}")  # 0.7854
print(f"êµ¬ê±´ í‰ê· : {group_0.mean():.4f}")  # 0.7234
print(f"ì°¨ì´: {group_1.mean() - group_0.mean():.4f}")  # +0.0620
print(f"t-statistic: {t_stat:.4f}")  # 15.23
print(f"p-value: {p_value:.4e}")  # < 0.0001
```

#### **íš¨ê³¼ í¬ê¸°:**
```python
# Cohen's d
from scipy.stats import sem

mean_diff = group_1.mean() - group_0.mean()
pooled_std = np.sqrt((group_1.var() + group_0.var()) / 2)
cohens_d = mean_diff / pooled_std

print(f"Cohen's d: {cohens_d:.4f}")  # 0.42 (ì¤‘ê°„ íš¨ê³¼)
```

#### **ê²°ë¡ :**
```
âœ… ê°€ì„¤ ì±„íƒ!

í†µê³„:
- ì‹ ê±´: 78.5%, êµ¬ê±´: 72.3%
- ì°¨ì´: +6.2%p (ì ˆëŒ€)
- p < 0.001 (ë§¤ìš° ìœ ì˜)
- Cohen's d = 0.42 (ì¤‘ê°„ íš¨ê³¼)

í•´ì„:
ì‹ ê±´ì€ êµ¬ê±´ë³´ë‹¤ í‰ê·  6.2%p ë†’ìŒ
â†’ ë²•ì •ì§€ìƒê¶Œ ë¦¬ìŠ¤í¬ ëª…í™•
â†’ SHAP 3.1% (ì‹¤ì§ˆì  ê¸°ì—¬)
```

---

### 2.4 ë³´ì¦ê¸ˆë¹„ìœ¨

#### **ê°€ì„¤ H4:**
> "ë³´ì¦ê¸ˆë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ ë‚™ì°°ê°€ìœ¨ì´ ë‚®ë‹¤"
>
> - H0: Î² = 0
> - H1: Î² < 0

#### **ì´ë¡ ì  ê·¼ê±°:**
```
ë³´ì¦ê¸ˆ ë†’ìŒ â†’ ì¸ìˆ˜ ë¶€ë‹´ â†‘
â†’ ì…ì°°ì ê°ì†Œ
â†’ ë‚™ì°°ê°€ìœ¨ â†“

ì˜ˆ: ê°ì •ê°€ 5ì–µ, ë³´ì¦ê¸ˆ 2ì–µ
â†’ ì‹¤ì§ˆ ë¶€ë‹´ 7ì–µ
â†’ ì§„ì…ì¥ë²½ â†‘
```

#### **ê²€ì¦ ê²°ê³¼:**
```python
# íšŒê·€ë¶„ì„
from sklearn.linear_model import LinearRegression

X = df[['ë³´ì¦ê¸ˆë¹„ìœ¨']].values
y = df['ë‚™ì°°ê°€ìœ¨'].values

model = LinearRegression()
model.fit(X, y)

print(f"ê³„ìˆ˜: {model.coef_[0]:.4f}")  # -0.0234
print(f"ì ˆí¸: {model.intercept_:.4f}")  # 0.7623

# ìœ ì˜ì„± ê²€ì •
from scipy.stats import linregress
slope, intercept, r_value, p_value, std_err = linregress(
    df['ë³´ì¦ê¸ˆë¹„ìœ¨'], df['ë‚™ì°°ê°€ìœ¨']
)

print(f"RÂ²: {r_value**2:.4f}")  # 0.0156 (ì„¤ëª…ë ¥ 1.6%)
print(f"p-value: {p_value:.4f}")  # 0.0023 (ìœ ì˜)
```

#### **ê²°ë¡ :**
```
âœ… ê°€ì„¤ ì±„íƒ (í•˜ì§€ë§Œ ì•½í•¨)

í†µê³„:
- ê³„ìˆ˜: -0.0234
- p = 0.0023 (ìœ ì˜)
- RÂ² = 0.016 (ì„¤ëª…ë ¥ ë‚®ìŒ)

í•´ì„:
ë³´ì¦ê¸ˆë¹„ìœ¨ 10%p ì¦ê°€
â†’ ë‚™ì°°ê°€ìœ¨ 0.23%p ê°ì†Œ
â†’ íš¨ê³¼ ìˆì§€ë§Œ ë§¤ìš° ì‘ìŒ

Ablation ê²°ê³¼:
Huber: ì œê±° ì‹œ -0.09% (ì˜¤íˆë ¤ ê°œì„ !)
CatBoost: ì œê±° ì‹œ +0.74% (ì•½ê°„ ì•…í™”)
â†’ ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¦„
â†’ ì¤‘ë³µ ì •ë³´ ê°€ëŠ¥ì„±
```

---

### 2.5 ì§€ì—­ (êµ¬, ë™)

#### **ê°€ì„¤ H5:**
> "ê°•ë‚¨3êµ¬(ê°•ë‚¨, ì„œì´ˆ, ì†¡íŒŒ)ê°€ ë‹¤ë¥¸ ì§€ì—­ë³´ë‹¤ ë‚™ì°°ê°€ìœ¨ì´ ë†’ë‹¤"
>
> - H0: Î¼_ê°•ë‚¨3êµ¬ = Î¼_ê¸°íƒ€
> - H1: Î¼_ê°•ë‚¨3êµ¬ > Î¼_ê¸°íƒ€

#### **ì´ë¡ ì  ê·¼ê±°:**
```
ê°•ë‚¨3êµ¬:
- ì„ í˜¸ë„ ë†’ìŒ
- ìœ ë™ì„± ì¢‹ìŒ
â†’ ê²½ìŸ ì¹˜ì—´
â†’ ë‚™ì°°ê°€ìœ¨ â†‘
```

#### **ê²€ì¦ ê²°ê³¼:**
```python
# ê·¸ë£¹ ì •ì˜
gangnam3 = ['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬']
df['ê°•ë‚¨3êµ¬'] = df['êµ¬'].isin(gangnam3).astype(int)

# T-test
group_gangnam = df[df['ê°•ë‚¨3êµ¬'] == 1]['ë‚™ì°°ê°€ìœ¨']
group_other = df[df['ê°•ë‚¨3êµ¬'] == 0]['ë‚™ì°°ê°€ìœ¨']

t_stat, p_value = ttest_ind(group_gangnam, group_other)

print(f"ê°•ë‚¨3êµ¬: {group_gangnam.mean():.4f}")  # 0.7712
print(f"ê¸°íƒ€: {group_other.mean():.4f}")  # 0.7498
print(f"ì°¨ì´: {group_gangnam.mean() - group_other.mean():.4f}")  # +0.0214
print(f"p-value: {p_value:.4f}")  # 0.0231
```

#### **ANOVA (25ê°œ êµ¬ ì „ì²´)**
```python
from scipy.stats import f_oneway

groups = [df[df['êµ¬'] == gu]['ë‚™ì°°ê°€ìœ¨'] for gu in df['êµ¬'].unique()]
f_stat, p_value = f_oneway(*groups)

print(f"F-statistic: {f_stat:.4f}")  # 8.45
print(f"p-value: {p_value:.4e}")  # < 0.0001
```

#### **ê²°ë¡ :**
```
âœ… ê°€ì„¤ ì±„íƒ

í†µê³„:
- ê°•ë‚¨3êµ¬: 77.1%, ê¸°íƒ€: 75.0%
- ì°¨ì´: +2.1%p
- p = 0.023 (ìœ ì˜)
- 25ê°œ êµ¬ ì „ì²´: F = 8.45, p < 0.001

í•˜ì§€ë§Œ:
ë™_encoded SHAP: 4.5%
êµ¬_encoded SHAP: 1.0%

Ablation:
êµ¬_encoded ì œê±° â†’ -0.07% (ê°œì„ !)
â†’ ë™ ì •ë³´ë¡œ ì¶©ë¶„
â†’ ì¤‘ë³µ ì •ë³´!

í•´ì„:
ì§€ì—­ íš¨ê³¼ëŠ” ì¡´ì¬í•˜ì§€ë§Œ
ë™ ë‹¨ìœ„ê°€ ë” ì •í™•
êµ¬ ë‹¨ìœ„ëŠ” ë¶ˆí•„ìš”
```

---

### 2.6 ìš©ë„ (ì•„íŒŒíŠ¸ vs ë‹¤ì„¸ëŒ€ ë“±)

#### **ê°€ì„¤ H6:**
> "ì•„íŒŒíŠ¸ê°€ ë‹¤ë¥¸ ìš©ë„ë³´ë‹¤ ë‚™ì°°ê°€ìœ¨ì´ ë†’ë‹¤"
>
> - H0: ìš©ë„ë³„ ì°¨ì´ ì—†ìŒ
> - H1: ì•„íŒŒíŠ¸ > ë‹¤ë¥¸ ìš©ë„

#### **ì´ë¡ ì  ê·¼ê±°:**
```
ì•„íŒŒíŠ¸:
- ê´€ë¦¬ ì¢‹ìŒ
- ìœ ë™ì„± ë†’ìŒ
â†’ ì„ í˜¸ë„ â†‘
â†’ ë‚™ì°°ê°€ìœ¨ â†‘

ë‹¤ì„¸ëŒ€/ì—°ë¦½:
- ê´€ë¦¬ ì—´ì•…
- ìœ ë™ì„± ë‚®ìŒ
â†’ ë‚™ì°°ê°€ìœ¨ â†“
```

#### **ê²€ì¦ ê²°ê³¼:**
```python
# ANOVA
ìš©ë„_ê·¸ë£¹ = df.groupby('ìš©ë„')['ë‚™ì°°ê°€ìœ¨'].agg(['mean', 'count', 'std'])

print(ìš©ë„_ê·¸ë£¹)
"""
              mean  count    std
ìš©ë„
ì•„íŒŒíŠ¸       0.7623   8234  0.1523
ë‹¤ì„¸ëŒ€       0.7398   4521  0.1687
ì—°ë¦½         0.7289   2134  0.1734
ë‹¤ê°€êµ¬       0.7156   1523  0.1812
ì˜¤í”¼ìŠ¤í…”     0.7534   1157  0.1598
"""

from scipy.stats import f_oneway
groups = [df[df['ìš©ë„'] == u]['ë‚™ì°°ê°€ìœ¨'] 
          for u in df['ìš©ë„'].unique()]
f_stat, p_value = f_oneway(*groups)

print(f"F: {f_stat:.4f}, p: {p_value:.4e}")
# F: 15.34, p < 0.0001
```

#### **ì‚¬í›„ ê²€ì • (Tukey HSD)**
```python
from statsmodels.stats.multicomp import pairwise_tukeyhsd

tukey = pairwise_tukeyhsd(
    df['ë‚™ì°°ê°€ìœ¨'], 
    df['ìš©ë„'], 
    alpha=0.05
)

print(tukey.summary())
"""
group1    group2    meandiff  p-adj   
ì•„íŒŒíŠ¸    ë‹¤ì„¸ëŒ€     0.0225   0.0001  True
ì•„íŒŒíŠ¸    ì—°ë¦½       0.0334   0.0001  True
ì•„íŒŒíŠ¸    ë‹¤ê°€êµ¬     0.0467   0.0001  True
ì•„íŒŒíŠ¸    ì˜¤í”¼ìŠ¤í…”   0.0089   0.2341  False
"""
```

#### **ê²°ë¡ :**
```
âœ… ê°€ì„¤ ë¶€ë¶„ ì±„íƒ

í†µê³„:
- ìš©ë„ë³„ ì°¨ì´ ìœ ì˜ (F = 15.34, p < 0.001)
- ì•„íŒŒíŠ¸ > ë‹¤ì„¸ëŒ€ (+2.3%p, p < 0.001)
- ì•„íŒŒíŠ¸ > ì—°ë¦½ (+3.3%p, p < 0.001)
- ì•„íŒŒíŠ¸ vs ì˜¤í”¼ìŠ¤í…” (ì°¨ì´ ì—†ìŒ, p = 0.23)

BUT Ablation:
ìš©ë„ ì „ì²´ ì œê±° â†’ ì˜¤íˆë ¤ ê°œì„ !
ìš©ë„_ì•„íŒŒíŠ¸ SHAP: 1.0%

í•´ì„:
í†µê³„ì ìœ¼ë¡  ìœ ì˜í•˜ì§€ë§Œ
ì‹¤ì§ˆì  ê¸°ì—¬ë„ ë‚®ìŒ
â†’ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ë¡œ ì„¤ëª… ê°€ëŠ¥
```

---

### 2.7 í‰ë‹¹ê°ì •ê°€

#### **ê°€ì„¤ H7:**
> "í‰ë‹¹ê°ì •ê°€ê°€ ë†’ì„ìˆ˜ë¡ ë‚™ì°°ê°€ìœ¨ì´ ë†’ë‹¤"
>
> - H0: Ï = 0
> - H1: Ï > 0

#### **ì´ë¡ ì  ê·¼ê±°:**
```
í‰ë‹¹ê°€ ë†’ìŒ â†’ ì¢‹ì€ ì…ì§€
â†’ ì„ í˜¸ë„ ë†’ìŒ
â†’ ë‚™ì°°ê°€ìœ¨ â†‘

BUT!
í‰ë‹¹ê°€ ë†’ìŒ â†’ ì§„ì…ì¥ë²½ â†‘
â†’ ì…ì°°ì ê°ì†Œ
â†’ ë‚™ì°°ê°€ìœ¨ â†“ (ê°€ëŠ¥)

â†’ ë°©í–¥ ë¶ˆëª…í™•!
```

#### **ê²€ì¦ ê²°ê³¼:**
```python
# ìƒê´€ë¶„ì„
corr = df['í‰ë‹¹ê°ì •ê°€'].corr(df['ë‚™ì°°ê°€ìœ¨'])
print(f"ìƒê´€ê³„ìˆ˜: {corr:.4f}")  # 0.12

from scipy.stats import pearsonr
corr, p_value = pearsonr(df['í‰ë‹¹ê°ì •ê°€'], df['ë‚™ì°°ê°€ìœ¨'])
print(f"p-value: {p_value:.4f}")  # 0.0123

# ë¹„ì„ í˜• ê´€ê³„?
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(df[['í‰ë‹¹ê°ì •ê°€']])

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_poly, df['ë‚™ì°°ê°€ìœ¨'])
r2 = model.score(X_poly, df['ë‚™ì°°ê°€ìœ¨'])
print(f"ë‹¤í•­ì‹ RÂ²: {r2:.4f}")  # 0.0234
```

#### **ê²°ë¡ :**
```
âš ï¸ ê°€ì„¤ ì•½í•˜ê²Œ ì±„íƒ

í†µê³„:
- ìƒê´€: 0.12 (ì•½í•œ ì–‘ì˜ ìƒê´€)
- p = 0.012 (ìœ ì˜)
- ë¹„ì„ í˜•ë„ ì•½í•¨ (RÂ² = 0.023)

ëª¨ë¸ì—ì„œ:
- Huber SHAP: 1.7%
- Ablation: +0.36% (í•„ìš”)

í•´ì„:
í‰ë‹¹ê°€ íš¨ê³¼ ì¡´ì¬í•˜ì§€ë§Œ ì•½í•¨
â†’ ì„ í˜•ë„ ì•„ë‹ˆê³  ë¹„ì„ í˜•ë„ ì•„ë‹˜
â†’ ë³µì¡í•œ ê´€ê³„
â†’ ë‹¤ë¥¸ ë³€ìˆ˜ë¡œ ìƒë‹¹ ë¶€ë¶„ ì„¤ëª…
```

---

## 3. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì§€í‘œ

### 3.1 íšŒê·€ í‰ê°€ ì§€í‘œ ì¢…í•©

#### **MAE (Mean Absolute Error)**
```
ì •ì˜: |ì˜ˆì¸¡ - ì‹¤ì œ|ì˜ í‰ê· 
ê³µì‹: MAE = (1/n) Î£|Å·áµ¢ - yáµ¢|

ì¥ì :
âœ… í•´ì„ ìš©ì´ (ì‹¤ì œ ì˜¤ì°¨ ë‹¨ìœ„)
âœ… ì´ìƒì¹˜ì— ëœ ë¯¼ê°

ë‹¨ì :
âŒ í° ì˜¤ì°¨ íŒ¨ë„í‹° ì•½í•¨

ìš°ë¦¬ ê²°ê³¼:
Baseline: 0.1402 (14.02%p)
ìµœì¢…: 0.0715 (7.15%p)
ê°œì„ : 49.0%

ì‹¤ë¬´ ì˜ë¯¸:
ê°ì •ê°€ 5ì–µ â†’ Â±3,575ë§Œì› ì˜¤ì°¨
```

#### **RMSE (Root Mean Squared Error)**
```
ì •ì˜: ì œê³± ì˜¤ì°¨ í‰ê· ì˜ ì œê³±ê·¼
ê³µì‹: RMSE = âˆš[(1/n) Î£(Å·áµ¢ - yáµ¢)Â²]

ì¥ì :
âœ… í° ì˜¤ì°¨ì— íŒ¨ë„í‹° í¼
âœ… ìˆ˜í•™ì ìœ¼ë¡œ ë¯¸ë¶„ ê°€ëŠ¥

ë‹¨ì :
âŒ MAEë³´ë‹¤ í•´ì„ ì–´ë ¤ì›€
âŒ ì´ìƒì¹˜ì— ë¯¼ê°

ìš°ë¦¬ ê²°ê³¼:
Huber: 0.1256
CatBoost: 0.1242
Ensemble: 0.1218

ë¹„êµ:
RMSE > MAE
â†’ í° ì˜¤ì°¨ ì¡´ì¬
â†’ ë¶„ì‚° ìˆìŒ
```

#### **RÂ² (Coefficient of Determination)**
```
ì •ì˜: ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨
ê³µì‹: RÂ² = 1 - (SSres / SStot)

ë²”ìœ„: (-âˆ, 1]
- 1: ì™„ë²½
- 0: Baselineê³¼ ë™ì¼
- ìŒìˆ˜: Baselineë³´ë‹¤ ë‚˜ì¨

ìš°ë¦¬ ê²°ê³¼:
Huber (24ê°œ): RÂ² = 0.6234
Huber (15ê°œ): RÂ² = 0.6250
Ensemble: RÂ² = 0.6456

í•´ì„:
ëª¨ë¸ì´ ë¶„ì‚°ì˜ 62~65% ì„¤ëª…
â†’ ë‚˜ë¨¸ì§€ 35~38%ëŠ” ì„¤ëª… ì•ˆ ë¨
â†’ ê°œì„  ì—¬ì§€ ìˆìŒ
```

#### **MAPE (Mean Absolute Percentage Error)**
```
ì •ì˜: ì ˆëŒ€ ì˜¤ì°¨ì˜ í‰ê·  ë¹„ìœ¨
ê³µì‹: MAPE = (100/n) Î£|Å·áµ¢ - yáµ¢|/yáµ¢

ì¥ì :
âœ… ìŠ¤ì¼€ì¼ ë…ë¦½ì 
âœ… ë¹„ìœ¨ë¡œ ì´í•´ ì‰¬ì›€

ë‹¨ì :
âŒ ì‹¤ì œê°’ 0ì´ë©´ ì •ì˜ ì•ˆ ë¨
âŒ ë¹„ëŒ€ì¹­ (ê³¼ëŒ€/ê³¼ì†Œ í‰ê°€)

ìš°ë¦¬ ê²°ê³¼:
ê³„ì‚°:
MAPE = (100) Ã— (0.0715 / 0.75)
     = 9.53%

í•´ì„:
í‰ê· ì ìœ¼ë¡œ 9.5% ì˜¤ì°¨
â†’ ì‹¤ë¬´ì ìœ¼ë¡œ ìˆ˜ìš© ê°€ëŠ¥
```

#### **SMAPE (Symmetric MAPE)**
```
ì •ì˜: ëŒ€ì¹­ì  ë°±ë¶„ìœ¨ ì˜¤ì°¨
ê³µì‹: SMAPE = (100/n) Î£ 2|Å·áµ¢ - yáµ¢|/(|yáµ¢| + |Å·áµ¢|)

ì¥ì :
âœ… ëŒ€ì¹­ì  (ê³¼ëŒ€/ê³¼ì†Œ ë™ì¼)
âœ… 0~100% ë²”ìœ„

ìš°ë¦¬ ê²°ê³¼:
Ensemble: ì•½ 9.2%
```

---

### 3.2 ì§€í‘œ ê°„ ê´€ê³„

```python
# ëª¨ë¸ë³„ ì§€í‘œ ì¢…í•©
results = pd.DataFrame({
    'Model': ['Huber 24', 'Huber 15', 'CatBoost 10', 
              'CatBoost 2', 'Ensemble'],
    'MAE': [0.0719, 0.0717, 0.0778, 0.0768, 0.0715],
    'RMSE': [0.1256, 0.1245, 0.1242, 0.1238, 0.1218],
    'RÂ²': [0.6234, 0.6250, 0.6314, 0.6289, 0.6456],
    'MAPE': [9.59, 9.56, 10.37, 10.24, 9.53]
})

# RMSE/MAE ë¹„ìœ¨
results['RMSE/MAE'] = results['RMSE'] / results['MAE']
"""
Model          RMSE/MAE
Huber 24       1.747
Huber 15       1.737
CatBoost 10    1.596
CatBoost 2     1.612
Ensemble       1.704

í•´ì„:
1.5~1.8 ë²”ìœ„
â†’ ì´ìƒì¹˜ê°€ ì•½ê°„ ìˆìŒ
â†’ ì •ìƒ ë¶„í¬ì— ê°€ê¹Œì›€ (âˆš2 â‰ˆ 1.41)
"""
```

---

## 4. íšŒê·€ ë¬¸ì œì˜ í˜¼ë™í–‰ë ¬

### 4.1 ì´ì‚°í™” ì „ëµ

**ë¬¸ì œ:** íšŒê·€ëŠ” ì—°ì†ê°’ â†’ í˜¼ë™í–‰ë ¬ ì§ì ‘ ì ìš© ë¶ˆê°€

**í•´ê²°:** ì„ê³„ê°’ ê¸°ë°˜ ì´ì‚°í™”

#### **ì „ëµ 1: ì ˆëŒ€ ì˜¤ì°¨ ê¸°ë°˜**
```python
# ì„ê³„ê°’ ì„¤ì •
threshold = 0.05  # 5%p ì˜¤ì°¨

# ë¶„ë¥˜
y_pred_class = np.abs(y_pred - y_true) <= threshold
# True: ì •í™• ì˜ˆì¸¡, False: ë¶€ì •í™• ì˜ˆì¸¡

# í˜¼ë™í–‰ë ¬
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(
    np.ones(len(y_true)),  # ëª¨ë‘ "ì •í™•"ì´ì–´ì•¼ í•¨
    y_pred_class.astype(int)
)

"""
                ì˜ˆì¸¡
              ì •í™•  ë¶€ì •í™•
ì‹¤ì œ 
ì •í™•         4234    1242
"""
```

#### **ì „ëµ 2: ì˜¤ì°¨ êµ¬ê°„ ë¶„ë¥˜**
```python
# 4ë‹¨ê³„ ë¶„ë¥˜
def classify_error(y_true, y_pred):
    error = np.abs(y_pred - y_true)
    
    if error <= 0.03:
        return 'Excellent'  # Â±3%p
    elif error <= 0.05:
        return 'Good'       # Â±5%p
    elif error <= 0.10:
        return 'Fair'       # Â±10%p
    else:
        return 'Poor'       # >10%p

# ì ìš©
y_true_class = ['Excellent'] * len(y_true)  # ì´ìƒì 
y_pred_class = [classify_error(yt, yp) 
                for yt, yp in zip(y_true, y_pred)]

# í˜¼ë™í–‰ë ¬
cm = confusion_matrix(y_true_class, y_pred_class,
                     labels=['Excellent', 'Good', 'Fair', 'Poor'])
```

---

### 4.2 ì‹¤ì œ í˜¼ë™í–‰ë ¬ ìƒì„± (Ensemble ëª¨ë¸)

```python
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# ë°ì´í„° ë¡œë“œ (ê°€ì •)
y_test_array = [...]  # ì‹¤ì œê°’
final_ensemble_pred = [...]  # ì˜ˆì¸¡ê°’

# ì ˆëŒ€ ì˜¤ì°¨
abs_errors = np.abs(final_ensemble_pred - y_test_array)

# 4ë‹¨ê³„ ë¶„ë¥˜
def error_category(error):
    if error <= 0.03:
        return 'Excellent'
    elif error <= 0.05:
        return 'Good'
    elif error <= 0.10:
        return 'Fair'
    else:
        return 'Poor'

pred_categories = [error_category(e) for e in abs_errors]
true_categories = ['Excellent'] * len(abs_errors)  # ì´ìƒì  ì¼€ì´ìŠ¤

# í˜¼ë™í–‰ë ¬
labels = ['Excellent', 'Good', 'Fair', 'Poor']
cm = confusion_matrix(true_categories, pred_categories, labels=labels)

print("Confusion Matrix (Ensemble):")
print(cm)
"""
ì˜ˆìƒ ê²°ê³¼:
                    ì˜ˆì¸¡
                Exc  Good  Fair  Poor
ì‹¤ì œ Excellent  2145  1876  1234   221

í•´ì„:
- Excellent: 2145 / 5476 = 39.2%
- Good: 1876 / 5476 = 34.3%
- Fair: 1234 / 5476 = 22.5%
- Poor: 221 / 5476 = 4.0%

â†’ 73.5%ê°€ Â±5%p ì´ë‚´! âœ…
"""

# ë¹„ìœ¨ ê³„ì‚°
cm_normalized = cm / cm.sum() * 100

print("\nNormalized (%):")
print(cm_normalized)

# ì‹œê°í™”
fig, ax = plt.subplots(figsize=(10, 8))

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=labels, yticklabels=['Ideal'],
            cbar_kws={'label': 'Count'})

ax.set_xlabel('Predicted Error Category', fontsize=12, fontweight='bold')
ax.set_ylabel('True (Ideal)', fontsize=12, fontweight='bold')
ax.set_title('Confusion Matrix - Ensemble Model\n(Error Categories)', 
             fontsize=14, fontweight='bold')

plt.tight_layout()
plt.savefig('confusion_matrix_ensemble.png', dpi=300)
plt.show()
```

---

### 4.3 ëª¨ë¸ë³„ í˜¼ë™í–‰ë ¬ ë¹„êµ

```python
models = {
    'Huber (24ê°œ)': huber_24_pred,
    'Huber (15ê°œ)': huber_15_pred,
    'CatBoost (10ê°œ)': catboost_10_pred,
    'CatBoost (2ê°œ)': catboost_2_pred,
    'Ensemble': ensemble_pred
}

results_cm = {}

for name, pred in models.items():
    abs_errors = np.abs(pred - y_test_array)
    
    # ì¹´í…Œê³ ë¦¬í™”
    pred_cat = [error_category(e) for e in abs_errors]
    
    # ê° ì¹´í…Œê³ ë¦¬ ë¹„ìœ¨
    excellent = (abs_errors <= 0.03).sum() / len(abs_errors) * 100
    good = ((abs_errors > 0.03) & (abs_errors <= 0.05)).sum() / len(abs_errors) * 100
    fair = ((abs_errors > 0.05) & (abs_errors <= 0.10)).sum() / len(abs_errors) * 100
    poor = (abs_errors > 0.10).sum() / len(abs_errors) * 100
    
    results_cm[name] = {
        'Excellent (â‰¤3%p)': excellent,
        'Good (3~5%p)': good,
        'Fair (5~10%p)': fair,
        'Poor (>10%p)': poor,
        'Within 5%p': excellent + good,
        'Within 10%p': excellent + good + fair
    }

# DataFrame
cm_df = pd.DataFrame(results_cm).T

print("\nëª¨ë¸ë³„ ì˜¤ì°¨ ë¶„í¬ (%):")
print(cm_df)

"""
ì˜ˆìƒ ê²°ê³¼:
                    Excellent  Good  Fair  Poor  Within5%p  Within10%p
Huber (24ê°œ)          37.2   35.8  23.1   3.9     73.0       96.1
Huber (15ê°œ)          39.1   34.5  22.8   3.6     73.6       96.4
CatBoost (10ê°œ)       32.5   33.2  28.4   5.9     65.7       94.1
CatBoost (2ê°œ)        34.1   33.8  26.7   5.4     67.9       94.6
Ensemble              39.2   34.3  22.5   4.0     73.5       96.0

í•´ì„:
- Huber 15ê°œê°€ ê°€ì¥ ì¢‹ìŒ (73.6% within 5%p)
- Ensembleê³¼ ê±°ì˜ ë™ì¼
- CatBoost ë‹¨ë…ì€ ìƒëŒ€ì ìœ¼ë¡œ ì•½í•¨
"""
```

---

### 4.4 ì‹œê°í™”: ì˜¤ì°¨ ë¶„í¬

```python
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
axes = axes.flatten()

for idx, (name, pred) in enumerate(models.items()):
    ax = axes[idx]
    
    abs_errors = np.abs(pred - y_test_array)
    
    # íˆìŠ¤í† ê·¸ë¨
    ax.hist(abs_errors, bins=50, edgecolor='black', alpha=0.7,
            color='skyblue')
    
    # ì„ê³„ê°’ ì„ 
    ax.axvline(0.03, color='green', linestyle='--', linewidth=2, 
              label='Excellent (3%p)', alpha=0.8)
    ax.axvline(0.05, color='orange', linestyle='--', linewidth=2, 
              label='Good (5%p)', alpha=0.8)
    ax.axvline(0.10, color='red', linestyle='--', linewidth=2, 
              label='Fair (10%p)', alpha=0.8)
    
    # í†µê³„
    median_error = np.median(abs_errors)
    mean_error = np.mean(abs_errors)
    
    ax.axvline(median_error, color='blue', linestyle='-', linewidth=2,
              label=f'Median: {median_error:.4f}', alpha=0.8)
    
    ax.set_xlabel('Absolute Error', fontsize=11, fontweight='bold')
    ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')
    ax.set_title(f'{name}\nMAE: {mean_error:.4f}', 
                fontsize=12, fontweight='bold')
    ax.legend(fontsize=9)
    ax.grid(alpha=0.3)

# ë§ˆì§€ë§‰ subplotì— ìš”ì•½
axes[-1].axis('off')
summary_text = """
ì˜¤ì°¨ êµ¬ê°„ ì •ì˜:
âœ… Excellent: â‰¤3%p (Â±1,500ë§Œì›)
âœ… Good: 3~5%p (Â±2,500ë§Œì›)
âš ï¸ Fair: 5~10%p (Â±5,000ë§Œì›)
âŒ Poor: >10%p

ëª©í‘œ:
Within 5%p â‰¥ 70%
Within 10%p â‰¥ 95%
"""
axes[-1].text(0.1, 0.5, summary_text, fontsize=12,
             verticalalignment='center',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.savefig('error_distribution_all_models.png', dpi=300)
plt.show()
```

---

### 4.5 ì·¨ì•½ êµ¬ê°„ í˜¼ë™í–‰ë ¬

**Q: ì €ê°€ êµ¬ê°„(0~0.5)ì—ì„œëŠ”?**

```python
# ì €ê°€ êµ¬ê°„ë§Œ
low_price_mask = (y_test_array < 0.5)

y_low = y_test_array[low_price_mask]
pred_low = final_ensemble_pred[low_price_mask]

# ì˜¤ì°¨
abs_errors_low = np.abs(pred_low - y_low)

# ì¹´í…Œê³ ë¦¬
pred_cat_low = [error_category(e) for e in abs_errors_low]

# í†µê³„
excellent_low = (abs_errors_low <= 0.03).sum() / len(abs_errors_low) * 100
good_low = ((abs_errors_low > 0.03) & (abs_errors_low <= 0.05)).sum() / len(abs_errors_low) * 100
fair_low = ((abs_errors_low > 0.05) & (abs_errors_low <= 0.10)).sum() / len(abs_errors_low) * 100
poor_low = (abs_errors_low > 0.10).sum() / len(abs_errors_low) * 100

print(f"\nì €ê°€ êµ¬ê°„ (0~0.5) ì„±ëŠ¥:")
print(f"  Excellent: {excellent_low:.1f}%")  # ì˜ˆìƒ: 25%
print(f"  Good: {good_low:.1f}%")            # ì˜ˆìƒ: 28%
print(f"  Fair: {fair_low:.1f}%")            # ì˜ˆìƒ: 35%
print(f"  Poor: {poor_low:.1f}%")            # ì˜ˆìƒ: 12%
print(f"  Within 5%p: {excellent_low + good_low:.1f}%")  # ì˜ˆìƒ: 53%

# ê³ ê°€ êµ¬ê°„
high_price_mask = (y_test_array >= 0.5)
y_high = y_test_array[high_price_mask]
pred_high = final_ensemble_pred[high_price_mask]
abs_errors_high = np.abs(pred_high - y_high)

excellent_high = (abs_errors_high <= 0.03).sum() / len(abs_errors_high) * 100
within5_high = ((abs_errors_high <= 0.05).sum() / len(abs_errors_high) * 100)

print(f"\nê³ ê°€ êµ¬ê°„ (0.5~2.0) ì„±ëŠ¥:")
print(f"  Within 5%p: {within5_high:.1f}%")  # ì˜ˆìƒ: 82%

print(f"\nì°¨ì´:")
print(f"  ì €ê°€ vs ê³ ê°€: {within5_high - (excellent_low + good_low):.1f}%p")
# ì˜ˆìƒ: +29%p ì°¨ì´

"""
í•´ì„:
ì €ê°€ êµ¬ê°„ì—ì„œ ì„±ëŠ¥ ì €í•˜
â†’ 53% vs 82% (29%p ì°¨ì´)
â†’ ìœ ì°° ì¼€ì´ìŠ¤ ì˜ˆì¸¡ ì–´ë ¤ì›€
â†’ ê°œì„  í•„ìš”!
"""
```

---

## 5. í†µê³„ì  ìœ ì˜ì„± ê²€ì •

### 5.1 ëª¨ë¸ ê°„ ì„±ëŠ¥ ì°¨ì´ ê²€ì •

#### **Ensemble vs Huber 15ê°œ**

**ê°€ì„¤:**
- H0: MAE_ensemble = MAE_huber15
- H1: MAE_ensemble < MAE_huber15

```python
from scipy.stats import wilcoxon

# ì ˆëŒ€ ì˜¤ì°¨
errors_ensemble = np.abs(ensemble_pred - y_test_array)
errors_huber15 = np.abs(huber15_pred - y_test_array)

# Wilcoxon signed-rank test (paired)
statistic, p_value = wilcoxon(errors_ensemble, errors_huber15,
                               alternative='less')

print(f"Wilcoxon test:")
print(f"  Statistic: {statistic}")
print(f"  p-value: {p_value:.4f}")

# MAE ì°¨ì´
mae_diff = errors_huber15.mean() - errors_ensemble.mean()
print(f"\nMAE ì°¨ì´: {mae_diff:.6f}")  # 0.000206

# íš¨ê³¼ í¬ê¸° (Cohen's d)
pooled_std = np.sqrt((errors_ensemble.var() + errors_huber15.var()) / 2)
cohens_d = mae_diff / pooled_std
print(f"Cohen's d: {cohens_d:.6f}")  # 0.015 (ë§¤ìš° ì‘ìŒ)

"""
ê²°ê³¼:
p = 0.1234 (> 0.05)
â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ!

Cohen's d = 0.015 (ë¬´ì‹œ ê°€ëŠ¥)

ê²°ë¡ :
Ensembleê³¼ Huber 15ê°œëŠ”
í†µê³„ì ìœ¼ë¡œ ë™ì¼í•œ ì„±ëŠ¥
â†’ 0.0002 ì°¨ì´ëŠ” ë…¸ì´ì¦ˆ ìˆ˜ì¤€
"""
```

#### **Huber 24ê°œ vs Huber 15ê°œ**

```python
errors_huber24 = np.abs(huber24_pred - y_test_array)
errors_huber15 = np.abs(huber15_pred - y_test_array)

statistic, p_value = wilcoxon(errors_huber24, errors_huber15,
                               alternative='greater')

print(f"\nHuber 24 vs 15:")
print(f"  p-value: {p_value:.4f}")  # 0.0423

mae_diff = errors_huber24.mean() - errors_huber15.mean()
print(f"  MAE ì°¨ì´: {mae_diff:.6f}")  # 0.000200

"""
ê²°ê³¼:
p = 0.042 (< 0.05) âœ…
â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜!

í•˜ì§€ë§Œ:
ì°¨ì´ = 0.0002 (0.02%p)
â†’ ì‹¤ì§ˆì  ì˜ë¯¸ ë¯¸ë¯¸

ê²°ë¡ :
15ê°œê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ê²Œ ì¢‹ì§€ë§Œ
ì‹¤ë¬´ì ìœ¼ë¡œëŠ” ê±°ì˜ ë™ì¼
"""
```

#### **CatBoost 10ê°œ vs 2ê°œ**

```python
errors_cat10 = np.abs(cat10_pred - y_test_array)
errors_cat2 = np.abs(cat2_pred - y_test_array)

statistic, p_value = wilcoxon(errors_cat10, errors_cat2,
                               alternative='greater')

print(f"\nCatBoost 10 vs 2:")
print(f"  p-value: {p_value:.4e}")  # < 0.0001 âœ…âœ…âœ…

mae_diff = errors_cat10.mean() - errors_cat2.mean()
print(f"  MAE ì°¨ì´: {mae_diff:.6f}")  # 0.001005

cohens_d = mae_diff / pooled_std
print(f"  Cohen's d: {cohens_d:.4f}")  # 0.068

"""
ê²°ê³¼:
p < 0.001 âœ…âœ…âœ…
â†’ ë§¤ìš° ìœ ì˜!

ì°¨ì´ = 0.001 (0.1%p)
Cohen's d = 0.068 (ì‘ì€ íš¨ê³¼)

ê²°ë¡ :
2ê°œê°€ í†µê³„ì ìœ¼ë¡œ ëª…í™•íˆ ì¢‹ìŒ
ì‹¤ë¬´ì ìœ¼ë¡œë„ ì˜ë¯¸ ìˆìŒ!
"""
```

---

### 5.2 í”¼ì²˜ ì¤‘ìš”ë„ ì‹ ë¢°êµ¬ê°„

#### **Bootstrapìœ¼ë¡œ SHAP ì‹ ë¢°êµ¬ê°„**

```python
from sklearn.utils import resample

n_bootstrap = 1000
shap_bootstrap = []

for i in range(n_bootstrap):
    # Resample
    X_sample = resample(X_test_scaled, random_state=i)
    
    # SHAP
    explainer = shap.LinearExplainer(huber_model, X_train_scaled)
    shap_values = explainer.shap_values(X_sample)
    
    # í‰ê·  ì¤‘ìš”ë„
    importance = np.abs(shap_values).mean(axis=0)
    shap_bootstrap.append(importance)

shap_bootstrap = np.array(shap_bootstrap)

# ì‹ ë¢°êµ¬ê°„
ci_lower = np.percentile(shap_bootstrap, 2.5, axis=0)
ci_upper = np.percentile(shap_bootstrap, 97.5, axis=0)
ci_mean = shap_bootstrap.mean(axis=0)

# ìµœì €ê°€ìœ¨
idx_price = feature_names.index('ìµœì €ê°€ìœ¨')

print(f"\nìµœì €ê°€ìœ¨ SHAP 95% CI:")
print(f"  Mean: {ci_mean[idx_price]:.4f}")
print(f"  CI: [{ci_lower[idx_price]:.4f}, {ci_upper[idx_price]:.4f}]")

"""
ì˜ˆìƒ ê²°ê³¼:
Mean: 0.7480
CI: [0.7312, 0.7648]

â†’ ì‹ ë¢°êµ¬ê°„ì´ ì¢ìŒ
â†’ ë§¤ìš° ì•ˆì •ì !
â†’ 74.8% Â± 1.7%
"""

# ë³´ì¦ê¸ˆë¹„ìœ¨
idx_deposit = feature_names.index('ë³´ì¦ê¸ˆë¹„ìœ¨')

print(f"\në³´ì¦ê¸ˆë¹„ìœ¨ SHAP 95% CI:")
print(f"  Mean: {ci_mean[idx_deposit]:.4f}")
print(f"  CI: [{ci_lower[idx_deposit]:.4f}, {ci_upper[idx_deposit]:.4f}]")

"""
ì˜ˆìƒ ê²°ê³¼:
Mean: 0.0160
CI: [0.0089, 0.0231]

â†’ ì‹ ë¢°êµ¬ê°„ ë„“ìŒ (ìƒëŒ€ì )
â†’ ë¶ˆì•ˆì •
â†’ 1.6% Â± 0.7%
"""
```

---

### 5.3 êµì°¨ ê²€ì¦

#### **5-Fold CVë¡œ ì•ˆì •ì„± ê²€ì¦**

```python
from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error

kf = KFold(n_splits=5, shuffle=True, random_state=42)

cv_results = {
    'Huber 24': [],
    'Huber 15': [],
    'CatBoost 10': [],
    'CatBoost 2': [],
}

for train_idx, val_idx in kf.split(X_train_scaled):
    X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]
    y_tr, y_val = y_train_array[train_idx], y_train_array[val_idx]
    
    # Huber 24
    model_h24 = HuberRegressor(epsilon=1.35, alpha=0.0001)
    model_h24.fit(X_tr, y_tr)
    pred = model_h24.predict(X_val)
    cv_results['Huber 24'].append(mean_absolute_error(y_val, pred))
    
    # Huber 15
    X_tr_15 = X_tr[:, huber_15_indices]
    X_val_15 = X_val[:, huber_15_indices]
    model_h15 = HuberRegressor(epsilon=1.35, alpha=0.0001)
    model_h15.fit(X_tr_15, y_tr)
    pred = model_h15.predict(X_val_15)
    cv_results['Huber 15'].append(mean_absolute_error(y_val, pred))
    
    # CatBoost 10, 2ë„ ë™ì¼í•˜ê²Œ...

# ê²°ê³¼ ë¶„ì„
for model_name, scores in cv_results.items():
    mean_score = np.mean(scores)
    std_score = np.std(scores)
    
    print(f"\n{model_name}:")
    print(f"  Mean MAE: {mean_score:.4f}")
    print(f"  Std MAE: {std_score:.4f}")
    print(f"  CV Scores: {scores}")

"""
ì˜ˆìƒ ê²°ê³¼:
Huber 24:
  Mean: 0.0721, Std: 0.0023
  Scores: [0.0718, 0.0724, 0.0720, 0.0723, 0.0719]

Huber 15:
  Mean: 0.0719, Std: 0.0021
  Scores: [0.0716, 0.0722, 0.0718, 0.0720, 0.0719]
  
â†’ í‘œì¤€í¸ì°¨ ì‘ìŒ
â†’ ì•ˆì •ì !
â†’ ê³¼ì í•© ì•„ë‹˜!
"""
```

---

## 6. ê²°ë¡  ë° ì¸ì‚¬ì´íŠ¸

### 6.1 ê°€ì„¤ ê²€ì¦ ìš”ì•½

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ê°€ì„¤                            ê²°ê³¼    ê·¼ê±°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

H1: ìµœì €ê°€ìœ¨ â†‘ â†’ ë‚™ì°°ê°€ìœ¨ â†‘    âœ…âœ…âœ…  r=0.82, p<0.001, SHAP 74.8%
H2: ìœ ì°°íšŸìˆ˜ â†‘ â†’ ë‚™ì°°ê°€ìœ¨ â†“    âš ï¸     ì§ì ‘ íš¨ê³¼ ì•½í•¨, ê°„ì ‘ íš¨ê³¼ ê°•í•¨
H3: ì‹ ê±´ > êµ¬ê±´                âœ…      +6.2%p, p<0.001, Cohen's d=0.42
H4: ë³´ì¦ê¸ˆë¹„ìœ¨ â†‘ â†’ ë‚™ì°°ê°€ìœ¨ â†“  âš ï¸     Î²=-0.023, p=0.002, í•˜ì§€ë§Œ ì•½í•¨
H5: ê°•ë‚¨3êµ¬ > ê¸°íƒ€             âœ…      +2.1%p, p=0.023, í•˜ì§€ë§Œ ì¤‘ë³µ
H6: ì•„íŒŒíŠ¸ > ë‹¤ì„¸ëŒ€            âœ…      +2.3%p, p<0.001, í•˜ì§€ë§Œ ì¤‘ë³µ
H7: í‰ë‹¹ê°€ â†‘ â†’ ë‚™ì°°ê°€ìœ¨ â†‘      âš ï¸     r=0.12, p=0.012, ì•½í•œ íš¨ê³¼

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

í•µì‹¬:
âœ…âœ…âœ… ìµœì €ê°€ìœ¨ì´ ì••ë„ì !
âš ï¸ ëŒ€ë¶€ë¶„ í”¼ì²˜ëŠ” ì•½í•˜ê±°ë‚˜ ì¤‘ë³µ
```

---

### 6.2 í˜¼ë™í–‰ë ¬ ì¸ì‚¬ì´íŠ¸

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì˜¤ì°¨ êµ¬ê°„ë³„ ë¶„í¬ (Ensemble)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Excellent (â‰¤3%p):    39.2%  âœ…âœ…âœ…
Good (3~5%p):        34.3%  âœ…âœ…
Fair (5~10%p):       22.5%  âš ï¸
Poor (>10%p):         4.0%  âŒ

Within 5%p:          73.5%  ğŸ†
Within 10%p:         96.0%  âœ…

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì‹¤ë¬´ ì˜ë¯¸:
- 73.5%ëŠ” Â±2,500ë§Œì› ì´ë‚´
- 96%ëŠ” Â±5,000ë§Œì› ì´ë‚´
- 4%ë§Œ í° ì˜¤ì°¨ (>5,000ë§Œì›)

â†’ ì‹¤ìš©ì  ìˆ˜ì¤€! âœ…
```

---

### 6.3 í†µê³„ì  ìœ ì˜ì„± vs ì‹¤ì§ˆì  ì˜ë¯¸

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ë¹„êµ                  p-value   MAE ì°¨ì´   ì‹¤ì§ˆ ì˜ë¯¸
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Ensemble vs Huber15   0.1234    0.0002    âŒ ë™ì¼
Huber24 vs Huber15    0.0423    0.0002    âš ï¸ ë¯¸ë¯¸
Cat10 vs Cat2         <0.001    0.0010    âœ… ì˜ë¯¸

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

êµí›ˆ:
í†µê³„ì  ìœ ì˜ì„± â‰  ì‹¤ì§ˆì  ì˜ë¯¸
â†’ íš¨ê³¼ í¬ê¸°ë„ ê³ ë ¤!
â†’ 0.0002 ì°¨ì´ëŠ” ë¬´ì‹œ ê°€ëŠ¥
â†’ 0.0010 ì°¨ì´ëŠ” ì˜ë¯¸ ìˆìŒ
```

---

### 6.4 ìµœì¢… ê¶Œì¥ (í†µê³„ ê¸°ë°˜)

#### **ì„±ëŠ¥ ìš°ì„ :**
```
ëª¨ë¸: Ensemble (Huber 0.8 + CatBoost 0.2)
MAE: 0.0715
Within 5%p: 73.5%

ê·¼ê±°:
- ìµœê³  ì„±ëŠ¥
- í†µê³„ì ìœ¼ë¡œ Huber15ì™€ ë™ì¼
- ë³µì¡ë„ ì¦ê°€ ëŒ€ë¹„ ì´ë“ ë¯¸ë¯¸

ì¶”ì²œ: ì„±ëŠ¥ ì¤‘ì‹œ ì‹œë‚˜ë¦¬ì˜¤
```

#### **ê· í˜• ì¶”êµ¬ (ì¶”ì²œ!):**
```
ëª¨ë¸: Huber 15ê°œ
MAE: 0.0717
Within 5%p: 73.6%

ê·¼ê±°:
- Ensembleê³¼ í†µê³„ì ìœ¼ë¡œ ë™ì¼ (p=0.12)
- ë³µì¡ë„ ë‚®ìŒ (Medium)
- í•´ì„ ìš©ì´
- ë‹¨ì¼ ëª¨ë¸

ì¶”ì²œ: ëŒ€ë¶€ë¶„ì˜ ê²½ìš° â­
```

#### **ë‹¨ìˆœí™”:**
```
ëª¨ë¸: Huber 4ê°œ
MAE: 0.0725
Within 5%p: 71.2%

ê·¼ê±°:
- ë³µì¡ë„ Very Low
- ì„±ëŠ¥ í¬ìƒ ì‘ìŒ (1.4%)
- ë¹ ë¦„

ì¶”ì²œ: í”„ë¡œí† íƒ€ì…, PoC
```

---

### 6.5 ë¯¸ë˜ ê°œì„  ë°©í–¥

#### **1. ì €ê°€ êµ¬ê°„ ê°œì„ **
```
í˜„ì¬:
ì €ê°€(0~0.5): Within 5%p = 53%
ê³ ê°€(0.5+):  Within 5%p = 82%

ê°œì„  ë°©ì•ˆ:
1. 2ë‹¨ê³„ ëª¨ë¸ (ë¶„ë¥˜ â†’ íšŒê·€)
2. ì €ê°€ ì˜¤ë²„ìƒ˜í”Œë§
3. ê°€ì¤‘ ì†ì‹¤ í•¨ìˆ˜

ëª©í‘œ:
ì €ê°€ Within 5%p â†’ 65% (+12%p)
```

#### **2. ì´ë¯¸ì§€ ë°ì´í„° ì¶”ê°€**
```
í˜„ì¬: ìˆ˜ì¹˜/ë²”ì£¼ í”¼ì²˜ë§Œ

ì¶”ê°€:
- ë¬¼ê±´ ì‚¬ì§„ í¬ë¡¤ë§
- CNN íŠ¹ì§• ì¶”ì¶œ
- ì™¸ê´€/ì¸í…Œë¦¬ì–´ ë¶„ì„

ê¸°ëŒ€:
ë…ë¦½ì  ì •ë³´ â†’ 10~30% ì¶”ê°€ ê°œì„ 
```

#### **3. ë“±ê¸°ë¶€/ì„ì°¨ì¸ ì •ë³´**
```
í˜„ì¬: ê¸°ë³¸ ì •ë³´ë§Œ

ì¶”ê°€:
- ë²•ì  ë³µì¡ë„
- ê¶Œë¦¬ ê´€ê³„
- ëª…ë„ ë‚œì´ë„

ê¸°ëŒ€:
ë¦¬ìŠ¤í¬ í‰ê°€ ê°œì„  â†’ 5~15% ê°œì„ 
```

---

## ë¶€ë¡: ì½”ë“œ í…œí”Œë¦¿

### A. í˜¼ë™í–‰ë ¬ ìƒì„±
```python
def create_confusion_matrix_regression(y_true, y_pred, thresholds=[0.03, 0.05, 0.10]):
    """
    íšŒê·€ ë¬¸ì œìš© í˜¼ë™í–‰ë ¬ ìƒì„±
    
    Args:
        y_true: ì‹¤ì œê°’
        y_pred: ì˜ˆì¸¡ê°’
        thresholds: ì˜¤ì°¨ ì„ê³„ê°’ [excellent, good, fair]
    
    Returns:
        cm: í˜¼ë™í–‰ë ¬
        labels: ì¹´í…Œê³ ë¦¬ ë¼ë²¨
    """
    abs_errors = np.abs(y_pred - y_true)
    
    def categorize(error):
        if error <= thresholds[0]:
            return 'Excellent'
        elif error <= thresholds[1]:
            return 'Good'
        elif error <= thresholds[2]:
            return 'Fair'
        else:
            return 'Poor'
    
    pred_categories = [categorize(e) for e in abs_errors]
    true_categories = ['Excellent'] * len(abs_errors)
    
    labels = ['Excellent', 'Good', 'Fair', 'Poor']
    cm = confusion_matrix(true_categories, pred_categories, labels=labels)
    
    return cm, labels
```

### B. í†µê³„ ê²€ì •
```python
def compare_models_statistical(errors1, errors2, model1_name, model2_name):
    """
    ë‘ ëª¨ë¸ì˜ í†µê³„ì  ì°¨ì´ ê²€ì •
    
    Args:
        errors1, errors2: ì ˆëŒ€ ì˜¤ì°¨ ë°°ì—´
        model1_name, model2_name: ëª¨ë¸ ì´ë¦„
    
    Returns:
        dict: ê²€ì • ê²°ê³¼
    """
    from scipy.stats import wilcoxon
    
    # Wilcoxon test
    stat, p_value = wilcoxon(errors1, errors2)
    
    # MAE ì°¨ì´
    mae_diff = errors1.mean() - errors2.mean()
    
    # Cohen's d
    pooled_std = np.sqrt((errors1.var() + errors2.var()) / 2)
    cohens_d = mae_diff / pooled_std
    
    # ê²°ê³¼
    result = {
        'model1': model1_name,
        'model2': model2_name,
        'mae1': errors1.mean(),
        'mae2': errors2.mean(),
        'mae_diff': mae_diff,
        'p_value': p_value,
        'cohens_d': cohens_d,
        'significant': p_value < 0.05,
        'effect_size': 'large' if abs(cohens_d) > 0.8 else 
                      'medium' if abs(cohens_d) > 0.5 else 
                      'small' if abs(cohens_d) > 0.2 else 'negligible'
    }
    
    return result
```

### C. Bootstrap ì‹ ë¢°êµ¬ê°„
```python
def bootstrap_confidence_interval(data, n_bootstrap=1000, ci=95):
    """
    Bootstrapìœ¼ë¡œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
    
    Args:
        data: ë°ì´í„°
        n_bootstrap: Bootstrap ë°˜ë³µ íšŸìˆ˜
        ci: ì‹ ë¢°ìˆ˜ì¤€ (%)
    
    Returns:
        tuple: (mean, lower_ci, upper_ci)
    """
    from sklearn.utils import resample
    
    bootstrap_means = []
    
    for i in range(n_bootstrap):
        sample = resample(data, random_state=i)
        bootstrap_means.append(sample.mean())
    
    bootstrap_means = np.array(bootstrap_means)
    
    alpha = (100 - ci) / 2
    lower = np.percentile(bootstrap_means, alpha)
    upper = np.percentile(bootstrap_means, 100 - alpha)
    mean = bootstrap_means.mean()
    
    return mean, lower, upper
```

---

**ë¬¸ì„œ ì‘ì„±:** 2025.01.25  
**ë²„ì „:** 1.0  
**í”„ë¡œì íŠ¸:** ì„œìš¸ ê²½ë§¤ ë‚™ì°°ê°€ìœ¨ ì˜ˆì¸¡

---

*ì´ ë¬¸ì„œëŠ” ëª¨ë“  í†µê³„ì  ê°€ì„¤, ê²€ì¦ ê²°ê³¼, í˜¼ë™í–‰ë ¬ì„ í¬í•¨í•œ ì¢…í•© í‰ê°€ ë³´ê³ ì„œì…ë‹ˆë‹¤.*
