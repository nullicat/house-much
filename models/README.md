# ğŸ¤– í•™ìŠµëœ ëª¨ë¸ íŒŒì¼

í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì€ ìš©ëŸ‰ ì œí•œìœ¼ë¡œ ê¹ƒí—ˆë¸Œì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

---

## ğŸ“¥ **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**

### **êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§í¬**
[ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (êµ¬ê¸€ ë“œë¼ì´ë¸Œ)](https://drive.google.com/drive/folders/1Bh5C93lrfTVpR_sExLlwCiKBcwT6zLwb).

---

## ğŸ“¦ **í•„ìš”í•œ ëª¨ë¸ íŒŒì¼**

### **2ë‹¨ê³„ ëª¨ë¸ (ìµœì¢… ì„ ì •)**

| íŒŒì¼ëª… | í¬ê¸° | ì„¤ëª… | ë‹¤ìš´ë¡œë“œ |
|--------|------|------|----------|
| `2stage_classifier.pkl` | 13.7MB | Stage 1: ë¶„ë¥˜ ëª¨ë¸ (ì •ìƒ vs ìœ ì°°) | â­ í•„ìˆ˜ |
| `2stage_huber_success.pkl` | 10KB | Stage 2-1: ì •ìƒ ê·¸ë£¹ íšŒê·€ ëª¨ë¸ | â­ í•„ìˆ˜ |
| `2stage_huber_fail.pkl` | 2KB | Stage 2-2: ìœ ì°° ê·¸ë£¹ íšŒê·€ ëª¨ë¸ | â­ í•„ìˆ˜ |

### **ê¸°íƒ€ ëª¨ë¸ (ì‹¤í—˜ìš©)**

| íŒŒì¼ëª… | í¬ê¸° | ì„¤ëª… |
|--------|------|------|
| `checkpoint.pkl` | 9.8MB | ì¤‘ê°„ ì‹¤í—˜ ê²°ê³¼ ë°±ì—… (ì„ íƒ) |
| `bert_embeddings.pkl` | 47.1MB | BERT ì„ë² ë”© (NLP ì‹¤í—˜ìš©) |
| `pycaret_best_model.pkl` | 15KB | PyCaret AutoML ê²°ê³¼ |
| `catboost_model.cbm` | 659KB | CatBoost ëª¨ë¸ |
| `linear_model.pkl` | 788B | ì„ í˜• íšŒê·€ ë² ì´ìŠ¤ë¼ì¸ |

---

## ğŸš€ **ëª¨ë¸ ì‚¬ìš© ë°©ë²•**

### **1. ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ**

```bash
# êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ë‹¤ìš´ë¡œë“œ
# â†’ models/ í´ë”ì— ì €ì¥
cd models/
# íŒŒì¼ ë³µì‚¬:
# - 2stage_classifier.pkl
# - 2stage_huber_success.pkl
# - 2stage_huber_fail.pkl
```

### **2. Pythonì—ì„œ ëª¨ë¸ ë¡œë“œ**

```python
import joblib
import numpy as np
from sklearn.preprocessing import StandardScaler

# ëª¨ë¸ ë¡œë“œ
clf = joblib.load('models/2stage_classifier.pkl')
huber_success = joblib.load('models/2stage_huber_success.pkl')
huber_fail = joblib.load('models/2stage_huber_fail.pkl')

# ë°ì´í„° ì¤€ë¹„ (ì˜ˆì‹œ)
X_new = np.array([[0.8]])  # ìµœì €ê°€ìœ¨
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_new)

# Stage 1: ë¶„ë¥˜
group_pred = clf.predict(X_scaled)  # 0: ì •ìƒ, 1: ìœ ì°°

# Stage 2: íšŒê·€
if group_pred == 0:
    ratio_pred = huber_success.predict(X_scaled)[0]
else:
    ratio_pred = huber_fail.predict(X_scaled)[0]

print(f"ì˜ˆì¸¡ ê·¸ë£¹: {'ì •ìƒ' if group_pred == 0 else 'ìœ ì°°'}")
print(f"ì˜ˆì¸¡ ë‚™ì°°ê°€ìœ¨: {ratio_pred:.4f}")
```

---

## ğŸ”„ **ëª¨ë¸ ì¬í•™ìŠµ**

ëª¨ë¸ì„ ì²˜ìŒë¶€í„° ì¬í•™ìŠµí•˜ë ¤ë©´:

```bash
# Jupyter ë…¸íŠ¸ë¶ ì‹¤í–‰
jupyter notebook notebooks/3_ëª¨ë¸ë§_ìµœì¢….ipynb

# ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸
python src/model.py --train
```

---

## ğŸ“Š **ëª¨ë¸ ì•„í‚¤í…ì²˜**

### **Stage 1: RandomForest Classifier**
```
ëª©ì : ì •ìƒ ê·¸ë£¹ vs ìœ ì°° ê·¸ë£¹ ë¶„ë¥˜
ì•Œê³ ë¦¬ì¦˜: RandomForestClassifier
í•˜ì´í¼íŒŒë¼ë¯¸í„°:
- n_estimators: 1000
- max_depth: 15
- class_weight: 'balanced'
- random_state: 42

ì„±ëŠ¥ (2025ë…„ ê²€ì¦):
- Accuracy: 97.0%
- Precision: 0.655
- Recall: 0.828
```

### **Stage 2-1: Huber Regressor (ì •ìƒ ê·¸ë£¹)**
```
ëª©ì : ì •ìƒ ê·¸ë£¹ ë‚™ì°°ê°€ìœ¨ ì˜ˆì¸¡
ì•Œê³ ë¦¬ì¦˜: HuberRegressor
í•˜ì´í¼íŒŒë¼ë¯¸í„°:
- epsilon: 1.35
- alpha: 0.0001 (L2 ì •ê·œí™”)
- max_iter: 100

ì„±ëŠ¥ (2025ë…„ ê²€ì¦):
- MAE: 0.0700
```

### **Stage 2-2: Huber Regressor (ìœ ì°° ê·¸ë£¹)**
```
ëª©ì : ìœ ì°° ê·¸ë£¹ ë‚™ì°°ê°€ìœ¨ ì˜ˆì¸¡
ì•Œê³ ë¦¬ì¦˜: HuberRegressor
í•˜ì´í¼íŒŒë¼ë¯¸í„°:
- epsilon: 1.1 (ì •ìƒ ê·¸ë£¹ê³¼ ë‹¤ë¦„!)
- alpha: 0.0001 (L2 ì •ê·œí™”)
- max_iter: 100

ì„±ëŠ¥ (2025ë…„ ê²€ì¦):
- MAE: 0.0401 â­
```

---

## ğŸ“ˆ **ëª¨ë¸ ì„±ëŠ¥**

### **2025ë…„ ê²€ì¦ ê²°ê³¼**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì „ì²´ MAE: 0.0686 (6.86%p ì˜¤ì°¨)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ë¶„ë¥˜ ì •í™•ë„: 97.0%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ê·¸ë£¹ë³„ ì„±ëŠ¥:
- ì •ìƒ ê·¸ë£¹ (â‰¥0.5): MAE 0.0700
- ìœ ì°° ê·¸ë£¹ (<0.5): MAE 0.0401 â­
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ’¡ **ë¬¸ì˜**

ëª¨ë¸ ì‚¬ìš© ì¤‘ ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì´ìŠˆë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.
- [GitHub Issues](https://github.com/your-username/seoul-auction-prediction/issues)

---

**â­ í”„ë¡œì íŠ¸ê°€ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ Starë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”! â­**
