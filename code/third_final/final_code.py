# ============================================================
# ğŸš€ 2ë‹¨ê³„ ëª¨ë¸ (ë¶„ë¥˜ â†’ íšŒê·€) + ìë™ ë¶„ì„ íŒŒì´í”„ë¼ì¸
# ============================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import HuberRegressor
from scipy.stats import wilcoxon
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("ğŸš€ 2ë‹¨ê³„ ëª¨ë¸ (ë¶„ë¥˜ â†’ íšŒê·€) + ìë™ ë¶„ì„ íŒŒì´í”„ë¼ì¸")
print("=" * 80)

# ============================================================
# [0] Checkpoint ë¡œë“œ
# ============================================================

print("\n[0] Checkpoint ë¡œë“œ")

import pickle

backup_dir = '/content/drive/MyDrive/auction_project_backup'

with open(f'{backup_dir}/checkpoint.pkl', 'rb') as f:
    checkpoint = pickle.load(f)

# ë°ì´í„° ì¶”ì¶œ
X_train = checkpoint['X_train']
X_test = checkpoint['X_test']
y_train = checkpoint['y_train']
y_test = checkpoint['y_test']

# Array ë³€í™˜
y_train_array = y_train.values if hasattr(y_train, 'values') else y_train
y_test_array = y_test.values if hasattr(y_test, 'values') else y_test

# ìŠ¤ì¼€ì¼ë§
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"   Train: {X_train.shape}")
print(f"   Test: {X_test.shape}")
print(f"   âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")

# Baseline ë¡œë“œ
baseline_pred = None
if 'final_ensemble_pred' in checkpoint:
    baseline_pred = checkpoint['final_ensemble_pred']
    print(f"   âœ… Baseline ë¡œë“œ ì™„ë£Œ")
elif 'ensemble_pred' in checkpoint:
    baseline_pred = checkpoint['ensemble_pred']
    print(f"   âœ… Baseline ë¡œë“œ ì™„ë£Œ (ensemble_pred)")
else:
    print(f"   âš ï¸ Baseline ì—†ìŒ")

# ============================================================
# [1] Stage 1: ë¶„ë¥˜ ëª¨ë¸ (ìœ ì°° vs ë‚™ì°°)
# ============================================================

print("\n" + "=" * 80)
print("[1] Stage 1: ë¶„ë¥˜ ëª¨ë¸ (ìœ ì°° vs ë‚™ì°°)")
print("=" * 80)

# ì„ê³„ê°’ ì„¤ì •
threshold = 0.5
y_class_train = (y_train_array < threshold).astype(int)
y_class_test = (y_test_array < threshold).astype(int)

print(f"\nì„ê³„ê°’: {threshold}")
print(f"ìœ ì°° ì¼€ì´ìŠ¤ (train): {y_class_train.sum()}ê°œ ({y_class_train.sum()/len(y_class_train)*100:.1f}%)")
print(f"ìœ ì°° ì¼€ì´ìŠ¤ (test): {y_class_test.sum()}ê°œ ({y_class_test.sum()/len(y_class_test)*100:.1f}%)")

# ë¶„ë¥˜ ëª¨ë¸ (RandomForest with tuning)
print("\në¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì¤‘...")

clf_params = {
    'n_estimators': 1000,
    'max_depth': 15,
    'min_samples_split': 10,
    'min_samples_leaf': 5,
    'max_features': 'sqrt',
    'class_weight': 'balanced',  # ë¶ˆê· í˜• ì²˜ë¦¬!
    'random_state': 42,
    'n_jobs': -1
}

clf = RandomForestClassifier(**clf_params)
clf.fit(X_train_scaled, y_class_train)

# ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€
y_class_pred_train = clf.predict(X_train_scaled)
y_class_pred_test = clf.predict(X_test_scaled)

print("\n[Train ë¶„ë¥˜ ì„±ëŠ¥]")
print(classification_report(y_class_train, y_class_pred_train,
                          target_names=['ë‚™ì°°', 'ìœ ì°°'],
                          digits=3))

print("\n[Test ë¶„ë¥˜ ì„±ëŠ¥]")
print(classification_report(y_class_test, y_class_pred_test,
                          target_names=['ë‚™ì°°', 'ìœ ì°°'],
                          digits=3))

# Confusion Matrix
cm = confusion_matrix(y_class_test, y_class_pred_test)
print("\n[Confusion Matrix]")
print(f"   TN: {cm[0,0]:4d}  FP: {cm[0,1]:4d}")
print(f"   FN: {cm[1,0]:4d}  TP: {cm[1,1]:4d}")

# ============================================================
# [2] Stage 2: ê·¸ë£¹ë³„ íšŒê·€ ëª¨ë¸
# ============================================================

print("\n" + "=" * 80)
print("[2] Stage 2: ê·¸ë£¹ë³„ íšŒê·€ ëª¨ë¸")
print("=" * 80)

# Train ê·¸ë£¹ ë¶„ë¦¬
fail_mask_train = (y_class_pred_train == 1)
success_mask_train = (y_class_pred_train == 0)

X_fail_train = X_train_scaled[fail_mask_train]
y_fail_train = y_train_array[fail_mask_train]

X_success_train = X_train_scaled[success_mask_train]
y_success_train = y_train_array[success_mask_train]

print(f"\n[Train ê·¸ë£¹ ë¶„ë¦¬]")
print(f"   ìœ ì°° ê·¸ë£¹: {len(X_fail_train)}ê°œ")
print(f"   ë‚™ì°° ê·¸ë£¹: {len(X_success_train)}ê°œ")

# 2.1 ìœ ì°° ê·¸ë£¹ ëª¨ë¸ (ì €ê°€ ì „ìš©)
print("\nìœ ì°° ê·¸ë£¹ ëª¨ë¸ í•™ìŠµ ì¤‘...")

huber_fail = HuberRegressor(
    epsilon=1.1,      # ë” ê³µê²©ì  (ì´ìƒì¹˜ì— ëœ ë¯¼ê°)
    alpha=0.00001,    # ì •ê·œí™” ì•½í•˜ê²Œ
    max_iter=500
)
huber_fail.fit(X_fail_train, y_fail_train)

# ê²€ì¦
fail_pred_train = huber_fail.predict(X_fail_train)
fail_mae_train = mean_absolute_error(y_fail_train, fail_pred_train)
print(f"   ìœ ì°° ê·¸ë£¹ Train MAE: {fail_mae_train:.4f}")

# 2.2 ë‚™ì°° ê·¸ë£¹ ëª¨ë¸ (ì •ìƒê°€ ì „ìš©)
print("\në‚™ì°° ê·¸ë£¹ ëª¨ë¸ í•™ìŠµ ì¤‘...")

huber_success = HuberRegressor(
    epsilon=1.35,     # ê¸°ë³¸ê°’
    alpha=0.0001,
    max_iter=200
)
huber_success.fit(X_success_train, y_success_train)

# ê²€ì¦
success_pred_train = huber_success.predict(X_success_train)
success_mae_train = mean_absolute_error(y_success_train, success_pred_train)
print(f"   ë‚™ì°° ê·¸ë£¹ Train MAE: {success_mae_train:.4f}")

print(f"\nâœ… Stage 2 í•™ìŠµ ì™„ë£Œ")

# ============================================================
# [3] 2ë‹¨ê³„ ì˜ˆì¸¡ (Test)
# ============================================================

print("\n" + "=" * 80)
print("[3] 2ë‹¨ê³„ ì˜ˆì¸¡")
print("=" * 80)

# Test ê·¸ë£¹ ë¶„ë¦¬
fail_mask_test = (y_class_pred_test == 1)
success_mask_test = (y_class_pred_test == 0)

print(f"\n[Test ê·¸ë£¹ ë¶„ë¦¬]")
print(f"   ìœ ì°° ì˜ˆì¸¡: {fail_mask_test.sum()}ê°œ")
print(f"   ë‚™ì°° ì˜ˆì¸¡: {success_mask_test.sum()}ê°œ")

# ê·¸ë£¹ë³„ ì˜ˆì¸¡
pred_2stage = np.zeros(len(X_test_scaled))

pred_2stage[success_mask_test] = huber_success.predict(
    X_test_scaled[success_mask_test]
)
pred_2stage[fail_mask_test] = huber_fail.predict(
    X_test_scaled[fail_mask_test]
)

print(f"\nâœ… 2ë‹¨ê³„ ì˜ˆì¸¡ ì™„ë£Œ")

# ============================================================
# [4] í‰ê°€
# ============================================================

print("\n" + "=" * 80)
print("[4] í‰ê°€")
print("=" * 80)

# ì „ì²´ ì„±ëŠ¥
mae_total = mean_absolute_error(y_test_array, pred_2stage)
print(f"\n[ì „ì²´ ì„±ëŠ¥]")
print(f"   2-Stage MAE: {mae_total:.4f}")

baseline_mae = 0.0715
improvement = (baseline_mae - mae_total) / baseline_mae * 100
print(f"   Baseline MAE: {baseline_mae:.4f}")
print(f"   ê°œì„ : {improvement:+.1f}%")

# ì €ê°€ êµ¬ê°„
low_mask = (y_test_array < 0.5)
mae_low = mean_absolute_error(y_test_array[low_mask], pred_2stage[low_mask])
baseline_low = 0.0805

print(f"\n[ì €ê°€ êµ¬ê°„ (ì‹¤ì œ ìœ ì°°)]")
print(f"   2-Stage MAE: {mae_low:.4f}")
print(f"   Baseline MAE: {baseline_low:.4f}")
print(f"   ê°œì„ : {(baseline_low - mae_low) / baseline_low * 100:+.1f}%")

# ê³ ê°€ êµ¬ê°„
high_mask = (y_test_array >= 0.5)
mae_high = mean_absolute_error(y_test_array[high_mask], pred_2stage[high_mask])
baseline_high = 0.0710  # Baseline ê³ ê°€ êµ¬ê°„

print(f"\n[ê³ ê°€ êµ¬ê°„ (ì‹¤ì œ ë‚™ì°°)]")
print(f"   2-Stage MAE: {mae_high:.4f}")
print(f"   Baseline MAE: {baseline_high:.4f}")
print(f"   ê°œì„ : {(baseline_high - mae_high) / baseline_high * 100:+.1f}%")

# Within 5%p
abs_errors = np.abs(pred_2stage - y_test_array)
within_5p_total = (abs_errors <= 0.05).sum() / len(abs_errors) * 100
within_5p_low = (abs_errors[low_mask] <= 0.05).sum() / low_mask.sum() * 100
within_5p_high = (abs_errors[high_mask] <= 0.05).sum() / high_mask.sum() * 100

print(f"\n[Within 5%p]")
print(f"   ì „ì²´: {within_5p_total:.1f}% (Baseline: 49.7%, {within_5p_total - 49.7:+.1f}%p)")
print(f"   ì €ê°€: {within_5p_low:.1f}% (Baseline: 25.7%, {within_5p_low - 25.7:+.1f}%p)")
print(f"   ê³ ê°€: {within_5p_high:.1f}% (Baseline: 51.1%, {within_5p_high - 51.1:+.1f}%p)")

# Within 10%p
within_10p_total = (abs_errors <= 0.10).sum() / len(abs_errors) * 100
print(f"\n[Within 10%p]")
print(f"   ì „ì²´: {within_10p_total:.1f}% (Baseline: 85.7%)")

# ============================================================
# [5] í†µê³„ì  ìœ ì˜ì„± ê²€ì •
# ============================================================

print("\n" + "=" * 80)
print("[5] í†µê³„ì  ìœ ì˜ì„± ê²€ì •")
print("=" * 80)

if baseline_pred is not None:
    # Wilcoxon Signed-Rank Test
    errors_baseline = np.abs(baseline_pred - y_test_array)
    errors_2stage = np.abs(pred_2stage - y_test_array)

    statistic, p_value = wilcoxon(errors_baseline, errors_2stage, alternative='greater')

    print(f"\n[Wilcoxon Signed-Rank Test]")
    print(f"   H0: Baseline â‰¤ 2-Stage")
    print(f"   H1: Baseline > 2-Stage (2-Stageê°€ ë” ì¢‹ìŒ)")
    print(f"   Statistic: {statistic:.0f}")
    print(f"   p-value: {p_value:.6f}")

    if p_value < 0.05:
        print(f"   âœ… ìœ ì˜ìˆ˜ì¤€ 0.05ì—ì„œ ìœ ì˜! (2-Stageê°€ í†µê³„ì ìœ¼ë¡œ ìš°ìˆ˜)")
    elif p_value < 0.10:
        print(f"   âš ï¸ ìœ ì˜ìˆ˜ì¤€ 0.10ì—ì„œ ìœ ì˜ (ì•½í•œ ì¦ê±°)")
    else:
        print(f"   âŒ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ")

    # Cohen's d (Effect Size)
    mean_diff = errors_baseline.mean() - errors_2stage.mean()
    pooled_std = np.sqrt((errors_baseline.std()**2 + errors_2stage.std()**2) / 2)
    cohens_d = mean_diff / pooled_std

    print(f"\n[Cohen's d (Effect Size)]")
    print(f"   Cohen's d: {cohens_d:.6f}")

    if abs(cohens_d) < 0.2:
        effect = "ë¬´ì‹œ ê°€ëŠ¥ (negligible)"
    elif abs(cohens_d) < 0.5:
        effect = "ì‘ìŒ (small)"
    elif abs(cohens_d) < 0.8:
        effect = "ì¤‘ê°„ (medium)"
    else:
        effect = "í¼ (large)"

    print(f"   íš¨ê³¼ í¬ê¸°: {effect}")

    # ì €ê°€ êµ¬ê°„ ë”°ë¡œ
    print(f"\n[ì €ê°€ êµ¬ê°„ Wilcoxon Test]")
    errors_baseline_low = errors_baseline[low_mask]
    errors_2stage_low = errors_2stage[low_mask]

    statistic_low, p_value_low = wilcoxon(errors_baseline_low, errors_2stage_low, alternative='greater')

    print(f"   Statistic: {statistic_low:.0f}")
    print(f"   p-value: {p_value_low:.6f}")

    if p_value_low < 0.05:
        print(f"   âœ… ì €ê°€ êµ¬ê°„ ê°œì„  ìœ ì˜!")
    else:
        print(f"   âš ï¸ ì €ê°€ êµ¬ê°„ ê°œì„  ë¯¸ë¯¸")

# ============================================================
# [6] í˜¼ë™í–‰ë ¬
# ============================================================

print("\n" + "=" * 80)
print("[6] í˜¼ë™í–‰ë ¬")
print("=" * 80)

def categorize_error(error):
    if error <= 0.03:
        return 'Excellent'
    elif error <= 0.05:
        return 'Good'
    elif error <= 0.10:
        return 'Fair'
    else:
        return 'Poor'

# 2-Stage
categories_2stage = [categorize_error(e) for e in abs_errors]
counts_2stage = Counter(categories_2stage)

total = len(abs_errors)

print("\n[2-Stage Model]")
print(f"   Excellent (â‰¤3%p): {counts_2stage['Excellent']/total*100:.1f}%")
print(f"   Good (3~5%p):     {counts_2stage['Good']/total*100:.1f}%")
print(f"   Fair (5~10%p):    {counts_2stage['Fair']/total*100:.1f}%")
print(f"   Poor (>10%p):     {counts_2stage['Poor']/total*100:.1f}%")

# Baseline ë¹„êµ
if baseline_pred is not None:
    categories_baseline = [categorize_error(e) for e in errors_baseline]
    counts_baseline = Counter(categories_baseline)

    print("\n[Baseline (Ensemble)]")
    print(f"   Excellent (â‰¤3%p): {counts_baseline['Excellent']/total*100:.1f}%")
    print(f"   Good (3~5%p):     {counts_baseline['Good']/total*100:.1f}%")
    print(f"   Fair (5~10%p):    {counts_baseline['Fair']/total*100:.1f}%")
    print(f"   Poor (>10%p):     {counts_baseline['Poor']/total*100:.1f}%")

    print("\n[ê°œì„ ìœ¨]")
    improvements = {
        'Excellent': (counts_2stage['Excellent'] - counts_baseline['Excellent'])/total*100,
        'Good': (counts_2stage['Good'] - counts_baseline['Good'])/total*100,
        'Fair': (counts_2stage['Fair'] - counts_baseline['Fair'])/total*100,
        'Poor': (counts_2stage['Poor'] - counts_baseline['Poor'])/total*100
    }

    for cat, imp in improvements.items():
        symbol = "âœ…" if (imp > 0 and cat in ['Excellent', 'Good']) or (imp < 0 and cat in ['Fair', 'Poor']) else "âš ï¸"
        print(f"   {cat:10s} {imp:+.1f}%p {symbol}")

# ì €ê°€ êµ¬ê°„ í˜¼ë™í–‰ë ¬
print("\n[ì €ê°€ êµ¬ê°„ í˜¼ë™í–‰ë ¬]")
categories_2stage_low = [categorize_error(e) for e in abs_errors[low_mask]]
counts_2stage_low = Counter(categories_2stage_low)

print(f"   Excellent (â‰¤3%p): {counts_2stage_low['Excellent']/low_mask.sum()*100:.1f}%")
print(f"   Good (3~5%p):     {counts_2stage_low['Good']/low_mask.sum()*100:.1f}%")
print(f"   Fair (5~10%p):    {counts_2stage_low['Fair']/low_mask.sum()*100:.1f}%")
print(f"   Poor (>10%p):     {counts_2stage_low['Poor']/low_mask.sum()*100:.1f}%")

# ============================================================
# [7] ì‹œê°í™” (12ê°œ)
# ============================================================

print("\n[7] ì‹œê°í™”")

fig = plt.figure(figsize=(24, 16))

# 1. ë¶„ë¥˜ Confusion Matrix
ax1 = plt.subplot(4, 3, 1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['ë‚™ì°°', 'ìœ ì°°'],
            yticklabels=['ë‚™ì°°', 'ìœ ì°°'],
            ax=ax1, cbar=False)
ax1.set_xlabel('Predicted', fontsize=10, fontweight='bold')
ax1.set_ylabel('Actual', fontsize=10, fontweight='bold')
ax1.set_title('Stage 1: ë¶„ë¥˜ ì„±ëŠ¥', fontsize=11, fontweight='bold')

# 2. í˜¼ë™í–‰ë ¬ ë¹„êµ (Baseline)
if baseline_pred is not None:
    ax2 = plt.subplot(4, 3, 2)
    categories = ['Excellent', 'Good', 'Fair', 'Poor']
    baseline_pcts = [counts_baseline[c]/total*100 for c in categories]

    bars = ax2.bar(range(len(categories)), baseline_pcts,
                   color=['green', 'lightgreen', 'orange', 'red'],
                   edgecolor='black', linewidth=2, alpha=0.8)

    ax2.set_xticks(range(len(categories)))
    ax2.set_xticklabels(categories, fontsize=9, fontweight='bold')
    ax2.set_ylabel('Percentage (%)', fontsize=10, fontweight='bold')
    ax2.set_title('Baseline\nWithin 5%p: 49.7%', fontsize=11, fontweight='bold')
    ax2.grid(alpha=0.3, axis='y')
    ax2.set_ylim(0, 50)

    for bar, pct in zip(bars, baseline_pcts):
        ax2.text(bar.get_x() + bar.get_width()/2, pct + 1,
                 f'{pct:.1f}%', ha='center', fontsize=8, fontweight='bold')

# 3. í˜¼ë™í–‰ë ¬ (2-Stage)
ax3 = plt.subplot(4, 3, 3)
stage_pcts = [counts_2stage[c]/total*100 for c in categories]

bars = ax3.bar(range(len(categories)), stage_pcts,
               color=['green', 'lightgreen', 'orange', 'red'],
               edgecolor='black', linewidth=2, alpha=0.8)

ax3.set_xticks(range(len(categories)))
ax3.set_xticklabels(categories, fontsize=9, fontweight='bold')
ax3.set_ylabel('Percentage (%)', fontsize=10, fontweight='bold')
ax3.set_title(f'2-Stage Model\nWithin 5%p: {within_5p_total:.1f}%',
              fontsize=11, fontweight='bold')
ax3.grid(alpha=0.3, axis='y')
ax3.set_ylim(0, 50)

for bar, pct in zip(bars, stage_pcts):
    ax3.text(bar.get_x() + bar.get_width()/2, pct + 1,
             f'{pct:.1f}%', ha='center', fontsize=8, fontweight='bold')

# 4. ì˜¤ì°¨ ë¶„í¬ ë¹„êµ
if baseline_pred is not None:
    ax4 = plt.subplot(4, 3, 4)
    ax4.hist(errors_baseline, bins=50, alpha=0.5, label='Baseline',
             color='blue', edgecolor='black')
    ax4.hist(abs_errors, bins=50, alpha=0.5, label='2-Stage',
             color='red', edgecolor='black')
    ax4.axvline(0.05, color='green', linestyle='--', linewidth=2, label='5%p')
    ax4.set_xlabel('Absolute Error', fontsize=10, fontweight='bold')
    ax4.set_ylabel('Frequency', fontsize=10, fontweight='bold')
    ax4.set_title('ì˜¤ì°¨ ë¶„í¬ ë¹„êµ', fontsize=11, fontweight='bold')
    ax4.legend()
    ax4.grid(alpha=0.3)

# 5. ì˜ˆì¸¡ vs ì‹¤ì œ (ì „ì²´)
ax5 = plt.subplot(4, 3, 5)
ax5.scatter(y_test_array, pred_2stage, alpha=0.3, s=10)
ax5.plot([0, 2], [0, 2], 'r--', linewidth=2, label='Perfect')
ax5.set_xlabel('ì‹¤ì œê°’', fontsize=10, fontweight='bold')
ax5.set_ylabel('ì˜ˆì¸¡ê°’', fontsize=10, fontweight='bold')
ax5.set_title(f'ì˜ˆì¸¡ vs ì‹¤ì œ (ì „ì²´)\nMAE: {mae_total:.4f}',
              fontsize=11, fontweight='bold')
ax5.legend()
ax5.grid(alpha=0.3)

# 6. ì˜ˆì¸¡ vs ì‹¤ì œ (ì €ê°€)
ax6 = plt.subplot(4, 3, 6)
ax6.scatter(y_test_array[low_mask], pred_2stage[low_mask],
            alpha=0.5, s=20, color='red')
ax6.plot([0, 0.5], [0, 0.5], 'r--', linewidth=2, label='Perfect')
ax6.set_xlabel('ì‹¤ì œê°’', fontsize=10, fontweight='bold')
ax6.set_ylabel('ì˜ˆì¸¡ê°’', fontsize=10, fontweight='bold')
ax6.set_title(f'ì˜ˆì¸¡ vs ì‹¤ì œ (ì €ê°€)\nMAE: {mae_low:.4f}',
              fontsize=11, fontweight='bold')
ax6.legend()
ax6.grid(alpha=0.3)

# 7. ëˆ„ì  ë¶„í¬ (CDF)
ax7 = plt.subplot(4, 3, 7)
sorted_errors = np.sort(abs_errors)
cdf = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors) * 100

ax7.plot(sorted_errors, cdf, linewidth=2, label='2-Stage')
if baseline_pred is not None:
    sorted_baseline = np.sort(errors_baseline)
    cdf_baseline = np.arange(1, len(sorted_baseline) + 1) / len(sorted_baseline) * 100
    ax7.plot(sorted_baseline, cdf_baseline, linewidth=2, alpha=0.7, label='Baseline')

ax7.axvline(0.05, color='green', linestyle='--', linewidth=2)
ax7.axvline(0.10, color='orange', linestyle='--', linewidth=2)
ax7.axhline(50, color='gray', linestyle=':', alpha=0.5)
ax7.set_xlabel('Absolute Error', fontsize=10, fontweight='bold')
ax7.set_ylabel('Cumulative %', fontsize=10, fontweight='bold')
ax7.set_title('ëˆ„ì  ì˜¤ì°¨ ë¶„í¬ (CDF)', fontsize=11, fontweight='bold')
ax7.legend()
ax7.grid(alpha=0.3)

# 8. êµ¬ê°„ë³„ ì„±ëŠ¥
ax8 = plt.subplot(4, 3, 8)
bins = [0, 0.01, 0.03, 0.05, 0.07, 0.10, 0.15, 0.20, 1.0]
labels = ['0-1%', '1-3%', '3-5%', '5-7%', '7-10%', '10-15%', '15-20%', '>20%']
error_dist = pd.cut(abs_errors, bins=bins, labels=labels).value_counts().sort_index()

bars = ax8.bar(range(len(error_dist)), error_dist.values / len(abs_errors) * 100,
               color=['darkgreen', 'green', 'lightgreen', 'yellow',
                      'orange', 'darkorange', 'red', 'darkred'],
               edgecolor='black', alpha=0.8)

ax8.set_xticks(range(len(error_dist)))
ax8.set_xticklabels(labels, rotation=45, fontsize=8)
ax8.set_ylabel('Percentage (%)', fontsize=10, fontweight='bold')
ax8.set_title('êµ¬ê°„ë³„ ì˜¤ì°¨ ë¶„í¬', fontsize=11, fontweight='bold')
ax8.grid(alpha=0.3, axis='y')

for bar, val in zip(bars, error_dist.values / len(abs_errors) * 100):
    if val > 0.5:
        ax8.text(bar.get_x() + bar.get_width()/2, val + 0.5,
                 f'{val:.1f}%', ha='center', fontsize=7)

# 9. ì €ê°€ êµ¬ê°„ í˜¼ë™í–‰ë ¬
ax9 = plt.subplot(4, 3, 9)
low_pcts = [counts_2stage_low[c]/low_mask.sum()*100 for c in categories]

bars = ax9.bar(range(len(categories)), low_pcts,
               color=['green', 'lightgreen', 'orange', 'red'],
               edgecolor='black', linewidth=2, alpha=0.8)

ax9.set_xticks(range(len(categories)))
ax9.set_xticklabels(categories, fontsize=9, fontweight='bold')
ax9.set_ylabel('Percentage (%)', fontsize=10, fontweight='bold')
ax9.set_title(f'ì €ê°€ êµ¬ê°„ í˜¼ë™í–‰ë ¬\nWithin 5%p: {within_5p_low:.1f}%',
              fontsize=11, fontweight='bold')
ax9.grid(alpha=0.3, axis='y')
ax9.set_ylim(0, 50)

for bar, pct in zip(bars, low_pcts):
    ax9.text(bar.get_x() + bar.get_width()/2, pct + 1,
             f'{pct:.1f}%', ha='center', fontsize=8, fontweight='bold')

# 10. ê·¸ë£¹ë³„ ì„±ëŠ¥ ë¹„êµ
ax10 = plt.subplot(4, 3, 10)
groups = ['ì „ì²´', 'ì €ê°€', 'ê³ ê°€']
baseline_vals = [0.0715, 0.0805, 0.0710]
stage_vals = [mae_total, mae_low, mae_high]

x = np.arange(len(groups))
width = 0.35

bars1 = ax10.bar(x - width/2, baseline_vals, width, label='Baseline',
                 color='skyblue', edgecolor='black', alpha=0.8)
bars2 = ax10.bar(x + width/2, stage_vals, width, label='2-Stage',
                 color='salmon', edgecolor='black', alpha=0.8)

ax10.set_ylabel('MAE', fontsize=10, fontweight='bold')
ax10.set_title('ê·¸ë£¹ë³„ MAE ë¹„êµ', fontsize=11, fontweight='bold')
ax10.set_xticks(x)
ax10.set_xticklabels(groups, fontsize=9, fontweight='bold')
ax10.legend()
ax10.grid(alpha=0.3, axis='y')

for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax10.text(bar.get_x() + bar.get_width()/2, height,
                 f'{height:.4f}', ha='center', va='bottom', fontsize=8)

# 11. Within 5%p ë¹„êµ
ax11 = plt.subplot(4, 3, 11)
groups = ['ì „ì²´', 'ì €ê°€', 'ê³ ê°€']
baseline_vals = [49.7, 25.7, 51.1]
stage_vals = [within_5p_total, within_5p_low, within_5p_high]

x = np.arange(len(groups))

bars1 = ax11.bar(x - width/2, baseline_vals, width, label='Baseline',
                 color='skyblue', edgecolor='black', alpha=0.8)
bars2 = ax11.bar(x + width/2, stage_vals, width, label='2-Stage',
                 color='salmon', edgecolor='black', alpha=0.8)

ax11.set_ylabel('Within 5%p (%)', fontsize=10, fontweight='bold')
ax11.set_title('ê·¸ë£¹ë³„ Within 5%p ë¹„êµ', fontsize=11, fontweight='bold')
ax11.set_xticks(x)
ax11.set_xticklabels(groups, fontsize=9, fontweight='bold')
ax11.legend()
ax11.grid(alpha=0.3, axis='y')

for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax11.text(bar.get_x() + bar.get_width()/2, height,
                 f'{height:.1f}%', ha='center', va='bottom', fontsize=8)

# 12. ê°œì„ ìœ¨ ìš”ì•½
ax12 = plt.subplot(4, 3, 12)
ax12.axis('off')

if baseline_pred is not None:
    summary_text = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        2ë‹¨ê³„ ëª¨ë¸ ê°œì„  ìš”ì•½
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[ì „ì²´ ì„±ëŠ¥]
MAE: {baseline_mae:.4f} â†’ {mae_total:.4f}
ê°œì„ : {improvement:+.1f}%

[ì €ê°€ êµ¬ê°„]
MAE: {baseline_low:.4f} â†’ {mae_low:.4f}
ê°œì„ : {(baseline_low - mae_low) / baseline_low * 100:+.1f}%

Within 5%p: {25.7:.1f}% â†’ {within_5p_low:.1f}%
ê°œì„ : {within_5p_low - 25.7:+.1f}%p

[Within 5%p]
ì „ì²´: {49.7:.1f}% â†’ {within_5p_total:.1f}%
ê°œì„ : {within_5p_total - 49.7:+.1f}%p

[í˜¼ë™í–‰ë ¬]
Fair: {counts_baseline['Fair']/total*100:.1f}% â†’ {counts_2stage['Fair']/total*100:.1f}%
Poor: {counts_baseline['Poor']/total*100:.1f}% â†’ {counts_2stage['Poor']/total*100:.1f}%

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
else:
    summary_text = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        2ë‹¨ê³„ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[ì „ì²´ ì„±ëŠ¥]
MAE: {mae_total:.4f}
ê°œì„ : {improvement:+.1f}%

[ì €ê°€ êµ¬ê°„] â­
MAE: {mae_low:.4f}
ê°œì„ : {(baseline_low - mae_low) / baseline_low * 100:+.1f}%

Within 5%p: {within_5p_low:.1f}%
ê°œì„ : {within_5p_low - 25.7:+.1f}%p

[Within 5%p]
ì „ì²´: {within_5p_total:.1f}%
ê°œì„ : {within_5p_total - 49.7:+.1f}%p

[ì €ê°€ í˜¼ë™í–‰ë ¬]
Excellent: {counts_2stage_low['Excellent']/low_mask.sum()*100:.1f}%
Good: {counts_2stage_low['Good']/low_mask.sum()*100:.1f}%
Fair: {counts_2stage_low['Fair']/low_mask.sum()*100:.1f}%
Poor: {counts_2stage_low['Poor']/low_mask.sum()*100:.1f}%

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

ax12.text(0.1, 0.5, summary_text, fontsize=10, family='monospace',
          verticalalignment='center')

plt.tight_layout()
plt.savefig(f'{backup_dir}/2stage_results_complete.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"   âœ… ì €ì¥: 2stage_results_complete.png")

# ============================================================
# [8] ìµœì¢… ìš”ì•½
# ============================================================

print("\n" + "=" * 80)
print("ğŸ† ìµœì¢… ìš”ì•½")
print("=" * 80)

print(f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                2ë‹¨ê³„ ëª¨ë¸ ìµœì¢… ì„±ëŠ¥
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[ì „ì²´ ì„±ëŠ¥]
Baseline MAE:       {baseline_mae:.4f}
2-Stage MAE:        {mae_total:.4f}
ê°œì„ :               {improvement:+.1f}%

[ì €ê°€ êµ¬ê°„] â­
Baseline MAE:       {baseline_low:.4f}
2-Stage MAE:        {mae_low:.4f}
ê°œì„ :               {(baseline_low - mae_low) / baseline_low * 100:+.1f}%

[ê³ ê°€ êµ¬ê°„]
Baseline MAE:       {baseline_high:.4f}
2-Stage MAE:        {mae_high:.4f}
ê°œì„ :               {(baseline_high - mae_high) / baseline_high * 100:+.1f}%

[Within 5%p]
Baseline (ì „ì²´):    49.7%
2-Stage (ì „ì²´):     {within_5p_total:.1f}% ({within_5p_total - 49.7:+.1f}%p)

Baseline (ì €ê°€):    25.7%
2-Stage (ì €ê°€):     {within_5p_low:.1f}% ({within_5p_low - 25.7:+.1f}%p) â­

Baseline (ê³ ê°€):    51.1%
2-Stage (ê³ ê°€):     {within_5p_high:.1f}% ({within_5p_high - 51.1:+.1f}%p)

[Within 10%p]
2-Stage:            {within_10p_total:.1f}%
Baseline:           85.7%

[í˜¼ë™í–‰ë ¬]
Excellent + Good:   {(counts_2stage['Excellent'] + counts_2stage['Good'])/total*100:.1f}%
Fair:               {counts_2stage['Fair']/total*100:.1f}%
Poor:               {counts_2stage['Poor']/total*100:.1f}%

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""")

# í‰ê°€
if improvement > 3:
    print("ğŸ‰ğŸ‰ğŸ‰ ì „ì²´ ì„±ëŠ¥ ê°œì„ ! 2ë‹¨ê³„ ëª¨ë¸ íš¨ê³¼ í™•ì¸!")
elif improvement > 1:
    print("âœ… ì „ì²´ ì„±ëŠ¥ ì†Œí­ ê°œì„ ")
else:
    print("âš ï¸ ì „ì²´ ì„±ëŠ¥ ë¹„ìŠ·")

if (baseline_low - mae_low) / baseline_low * 100 > 10:
    print("ğŸ‰ğŸ‰ğŸ‰ ì €ê°€ êµ¬ê°„ ëŒ€í­ ê°œì„ ! 2ë‹¨ê³„ ëª¨ë¸ì˜ í•µì‹¬ ì„±ê³¼!")
elif (baseline_low - mae_low) / baseline_low * 100 > 5:
    print("âœ…âœ… ì €ê°€ êµ¬ê°„ ê°œì„ !")
else:
    print("âš ï¸ ì €ê°€ êµ¬ê°„ ê°œì„  ë¯¸ë¯¸")

if within_5p_low - 25.7 > 10:
    print(f"ğŸ‰ğŸ‰ğŸ‰ ì €ê°€ Within 5%p ëŒ€í­ ê°œì„ ! (+{within_5p_low - 25.7:.1f}%p)")
elif within_5p_low - 25.7 > 5:
    print(f"âœ…âœ… ì €ê°€ Within 5%p ê°œì„ ! (+{within_5p_low - 25.7:.1f}%p)")

print("\n" + "=" * 80)

# ============================================================
# [9] ê²°ê³¼ ì €ì¥
# ============================================================

print("\n[9] ê²°ê³¼ ì €ì¥")

# ëª¨ë¸ ì €ì¥
import joblib

joblib.dump(clf, f'{backup_dir}/2stage_classifier.pkl')
joblib.dump(huber_fail, f'{backup_dir}/2stage_huber_fail.pkl')
joblib.dump(huber_success, f'{backup_dir}/2stage_huber_success.pkl')

print(f"   âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

# ì˜ˆì¸¡ê°’ ì €ì¥
stage2_predictions = {
    'y_test': y_test_array,
    'pred': pred_2stage,
    'classifier_pred': y_class_pred_test,
    'mae_total': mae_total,
    'mae_low': mae_low,
    'mae_high': mae_high,
    'within_5p_total': within_5p_total,
    'within_5p_low': within_5p_low,
    'within_5p_high': within_5p_high,
    'within_10p_total': within_10p_total,
    'counts_2stage': counts_2stage,
    'counts_2stage_low': counts_2stage_low,
    'improvements': improvements if baseline_pred is not None else None
}

# Checkpointì— ì¶”ê°€
checkpoint['stage2_predictions'] = stage2_predictions

# ì €ì¥
with open(f'{backup_dir}/checkpoint.pkl', 'wb') as f:
    pickle.dump(checkpoint, f)

print(f"   âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: checkpoint.pklì— ì¶”ê°€")
print("\n" + "=" * 80)